{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3fbe99",
   "metadata": {},
   "source": [
    "# Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40aef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_english_alphabet=pickle.load(open('vocab_tools/index_to_english_alphabet.pickle', 'rb'))\n",
    "index_to_hindi_alphabet=pickle.load(open('vocab_tools/index_to_hindi_alphabet.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bc19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabet_to_index=pickle.load(open('vocab_tools/hindi_alphabet_to_index.pickle', 'rb')) \n",
    "english_alphabet_to_index=pickle.load(open('vocab_tools/english_alphabet_to_index.pickle', 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('simple_data/X_train.npy')\n",
    "X_valid=np.load('simple_data/X_val.npy')\n",
    "\n",
    "y_train=np.load('simple_data/y_train.npy')\n",
    "y_valid=np.load('simple_data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bb32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c997e",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e291758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng_Hind_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, in_file, out_file, root_dir='simple_data',device='cuda'):\n",
    "\n",
    "        self.input = torch.tensor(np.load(root_dir+'/'+in_file))\n",
    "        self.output = torch.tensor(np.load(root_dir+'/'+out_file))\n",
    "        \n",
    "        assert(len(self.input)==len(self.output),\"Error: I/O Lengths must be same\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        X=self.input[idx]\n",
    "        X=X.to(device)\n",
    "        y=self.output[idx]\n",
    "        y=y.to(device)\n",
    "        \n",
    "\n",
    "\n",
    "        sample = {'input': X, 'output': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d715496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6f5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=Eng_Hind_Dataset(\"X_train.npy\",\"y_train.npy\",device=device)\n",
    "val_data=Eng_Hind_Dataset(\"X_val.npy\",\"y_val.npy\",device=device)\n",
    "test_data=Eng_Hind_Dataset(\"X_test.npy\",\"y_test.npy\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9249f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sets = torch.utils.data.ConcatDataset([training_data, val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b576ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataloader = DataLoader(train_val_sets, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53944bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d97754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e383a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_type(mode:str='rnn'):\n",
    "    mode=mode.lower()\n",
    "    if mode == 'rnn':\n",
    "        return nn.RNN\n",
    "    elif mode =='gru':\n",
    "        return nn.GRU\n",
    "    else:\n",
    "        return nn.LSTM\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773442fb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e094b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, enc_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        \"\"\"\n",
    "        Encoder module for sequence-to-sequence model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : int\n",
    "            Input size, should be equal to the source vocabulary size.\n",
    "\n",
    "        enc_embed_size : int\n",
    "            Embedding layer's dimension.\n",
    "\n",
    "        hid_size : int\n",
    "            LSTM Hidden/Cell state's dimension.\n",
    "\n",
    "        num_layers : int\n",
    "            Number of LSTM layers.\n",
    "\n",
    "        cell_mode : str\n",
    "            Type of cell to use: LSTM, GRU, or RNN.\n",
    "\n",
    "        dropout : float\n",
    "            Dropout rate for the LSTM layer.\n",
    "\n",
    "        is_bi : bool\n",
    "            Whether the LSTM layer is bidirectional or not.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, enc_embed_size, padding_idx=english_alphabet_to_index['.'])\n",
    "\n",
    "        # Create LSTM/GRU/RNN cell\n",
    "        cell = cell_type(cell_mode)\n",
    "\n",
    "        self.cell = cell(enc_embed_size, hid_size, num_layers, dropout=dropout, bidirectional=is_bi, batch_first=True)\n",
    "        self.cell_mode = cell_mode\n",
    "\n",
    "    def forward(self, input_batch: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the Encoder module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_batch : torch.LongTensor\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    " \n",
    "        \n",
    "        hidden : torch.LongTensor\n",
    "            Hidden state of the LSTM layer. \n",
    "\n",
    "        cell : torch.LongTensor\n",
    "            Cell state of the LSTM layer. \n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_batch)  # [sent len, batch size, emb dim]\n",
    "\n",
    "        if self.cell_mode.lower() == 'lstm':\n",
    "            outputs, (hidden, cell) = self.cell(embedded)\n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded)\n",
    "            cell = outputs\n",
    "\n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761debd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, dec_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        \"\"\"\n",
    "        Decoder module for sequence-to-sequence model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        output_size : int\n",
    "            Output size, should be equal to the target vocabulary size.\n",
    "\n",
    "        dec_embed_size : int\n",
    "            Embedding layer's dimension.\n",
    "\n",
    "        hid_size : int\n",
    "            LSTM Hidden/Cell state's dimension.\n",
    "\n",
    "        num_layers : int\n",
    "            Number of LSTM layers.\n",
    "\n",
    "        cell_mode : str\n",
    "            Type of cell to use: LSTM, GRU, or RNN.\n",
    "\n",
    "        dropout : float\n",
    "            Dropout rate for the LSTM layer.\n",
    "\n",
    "        is_bi : bool\n",
    "            Whether the LSTM layer is bidirectional or not.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, dec_embed_size, padding_idx=hindi_alphabet_to_index['.'])\n",
    "\n",
    "        cell = cell_type(cell_mode)\n",
    "\n",
    "        self.cell = cell(dec_embed_size, hid_size, num_layers, dropout=dropout, bidirectional=is_bi, batch_first=True)\n",
    "        if is_bi:\n",
    "            self.out = nn.Linear(hid_size*2, output_size)\n",
    "        else:\n",
    "            self.out = nn.Linear(hid_size, output_size)\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.cell_mode = cell_mode\n",
    "\n",
    "    def forward(self, trg: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the Decoder module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trg : torch.LongTensor\n",
    "            Target tensor of shape [batch size].\n",
    "\n",
    "        hidden : torch.FloatTensor\n",
    "            Hidden state of the Encoder's LSTM layer.\n",
    "\n",
    "        cell : torch.FloatTensor\n",
    "            Cell state of the Encoder's LSTM layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction : torch.FloatTensor\n",
    "            Prediction tensor.\n",
    "\n",
    "        hidden : torch.FloatTensor\n",
    "            Hidden state of the Decoder's LSTM layer.\n",
    "\n",
    "        cell : torch.FloatTensor\n",
    "            Cell state of the Decoder's LSTM layer.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(trg.unsqueeze(1))\n",
    "\n",
    "        if self.cell_mode.lower() == 'lstm':\n",
    "            outputs, (hidden, cell) = self.cell(embedded, (hidden, cell))\n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded, hidden)\n",
    "            cell = hidden\n",
    "\n",
    "        prediction = self.out(outputs.squeeze(1))\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e441d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \"\"\"\n",
    "        Sequence-to-Sequence model consisting of an Encoder and Decoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoder : nn.Module\n",
    "            Encoder module.\n",
    "\n",
    "        decoder : nn.Module\n",
    "            Decoder module.\n",
    "\n",
    "        device : str\n",
    "            Device to run the model on (e.g., 'cpu', 'cuda').\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source_batch, target_batch, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Forward pass of the Seq2Seq model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source_batch : torch.LongTensor\n",
    "            Batched tokenized source sentences\n",
    "\n",
    "        target_batch : torch.LongTensor\n",
    "            Batched tokenized target sentences\n",
    "\n",
    "        teacher_forcing_ratio : float, optional\n",
    "            The probability of using teacher forcing during training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : torch.FloatTensor\n",
    "        \"\"\"\n",
    "        batch_size, max_len = target_batch.shape\n",
    "        target_vocab_size = self.decoder.output_size\n",
    "\n",
    "        # Tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "        # Last hidden and cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(source_batch)\n",
    "\n",
    "        trg = target_batch[:, 0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if np.random.random() < teacher_forcing_ratio:\n",
    "                trg = target_batch[:, i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f6133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(target_seq,seq2,mode='full',device=device):# predicted\n",
    "    eos_index=(target_seq==hindi_alphabet_to_index['>']).nonzero()\n",
    "    eos_idx=eos_index[:,1]\n",
    "    \n",
    "    correct=torch.Tensor([0]).to(device)\n",
    "    correct_chars=torch.Tensor([0]).to(device)\n",
    "    tot_chars=torch.Tensor([0]).to(device)\n",
    "    for iterate,idx in enumerate(eos_idx):\n",
    "        inputter=seq2[iterate][:idx]\n",
    "        outputter=target_seq[iterate][:idx]\n",
    "        if torch.all(torch.eq(inputter,outputter)):\n",
    "            correct+=1\n",
    "            correct_chars+=idx\n",
    "            tot_chars+=idx\n",
    "        else:\n",
    "            correct_chars+=torch.sum(inputter == outputter).item()\n",
    "            tot_chars+=idx\n",
    "            \n",
    "#         print(correct,correct_chars,tot_chars)\n",
    "        \n",
    "    return correct.item(),correct_chars.item(),tot_chars.item()\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87facdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Train the Seq2Seq model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq2seq : nn.Module\n",
    "        Seq2Seq model.\n",
    "\n",
    "    iterator : torch.utils.data.DataLoader\n",
    "        Data iterator.\n",
    "\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimizer for training.\n",
    "\n",
    "    criterion : nn.Module\n",
    "        Loss function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    epoch_loss : float\n",
    "        Average loss per epoch.\n",
    "\n",
    "    accuracy : float\n",
    "        Accuracy of the model (per sequence).\n",
    "\n",
    "    char_accuracy : float\n",
    "        Accuracy of the model (per character).\n",
    "    \"\"\"\n",
    "    seq2seq.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    correct_char = 0\n",
    "    tot_char = 0\n",
    "    relax_acc = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch['input'], batch['output'])\n",
    "        batch_label = batch['output'].transpose(0, 1)\n",
    "        batch_size = len(batch['output'])\n",
    "\n",
    "        _, predicted = torch.max(outputs, dim=2)\n",
    "        outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch_label.reshape(-1)\n",
    "\n",
    "        trg_flatten.requires_grad = False\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        correct_temp, correct_chars_temp, tot_chars_temp = accuracy_calc(batch['output'], predicted.transpose(0, 1))\n",
    "\n",
    "        correct += correct_temp\n",
    "        correct_char += correct_chars_temp\n",
    "        tot_char += tot_chars_temp\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), correct / (len(iterator) * 16), correct_char / tot_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a950559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            outputs = seq2seq(batch['input'], batch['output'],teacher_forcing_ratio=0)\n",
    "            batch_label=batch['output'].transpose(0,1)\n",
    "            batch_size=len(batch['output'])\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=2)\n",
    "            #print('wow_preds',predicted.shape)\n",
    "\n",
    "            outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "            trg_flatten = batch_label.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            \n",
    "            correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "            #___________\n",
    "\n",
    "            correct+=correct_temp\n",
    "            correct_char+=correct_chars_temp\n",
    "            tot_char+=tot_chars_temp\n",
    "\n",
    "            #_______________       \n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "718d4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    e_time = end_time - start_time\n",
    "    mins = e_time // 60\n",
    "    secs = e_time%60\n",
    "    return mins, secs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5eb08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d74d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd5bae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def make_model(train_iterator,valid_iterator, enc_embed_size,dec_embed_size,\n",
    "               hid_size, num_layers, cell_mode, dropout, is_bi, epochs=20):\n",
    "    E=Encoder(30, enc_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "    E=E.to(device)\n",
    "    \n",
    "    D=Decoder(68, dec_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "    \n",
    "    D=D.to(device)\n",
    "    S=Seq2Seq(E,D,device)\n",
    "    S.to(device)    \n",
    "    print(f'The model has {count_params(S):,} trainable parameters')\n",
    "    \n",
    "    optimizer = optim.Adam(S.parameters())\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hindi_alphabet_to_index['.'])\n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):    \n",
    "        start_time = time.time()\n",
    "        train_loss,train_acc,train_stuff = train(S, train_iterator, optimizer, criterion)\n",
    "        valid_loss,valid_acc,val_stuff = evaluate(S, valid_iterator, criterion)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(S.state_dict(), 'model1.pt')\n",
    "\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s')\n",
    "        print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print(f'\\t Relaxed Train. Acc: {train_stuff*100:.2f}% | Relaxed Val. Acc: {val_stuff*100:.2f}%')\n",
    "        \n",
    "    return S\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60327877",
   "metadata": {},
   "source": [
    "# Make custom model \n",
    "pass your data loaders, configurations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f239f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,936,324 trainable parameters\n",
      "Epoch: 01 | Time: 1.0m 18.74s\n",
      "\t Train Loss: 1.546 | Train Acc: 12.95%\n",
      "\t Val. Loss: 1.521 |  Val. Acc: 27.29%\n",
      "\t Relaxed Train. Acc: 64.22% | Relaxed Val. Acc: 68.21%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_iterator=train_val_dataloader\n",
    "valid_iterator=test_dataloader\n",
    "SS=make_model(train_iterator,valid_iterator,enc_embed_size=128, dec_embed_size=128,\n",
    "               hid_size=256, num_layers=3, cell_mode='lstm', dropout=0.3, is_bi=True, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae99ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to Save Model\n",
    "\n",
    "# torch.save(SS, 'noattn_model.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a446395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to laod model:\n",
    "\n",
    "# the_model = torch.load('noattn_model.model')\n",
    "the_model=SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452339cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_dataloader = DataLoader(test_data, batch_size=len(test_data),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e79ef338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on test dataset\n",
    "\n",
    "the_model.eval()\n",
    "preds=the_model(next(iter(test_full_dataloader))['input'],next(iter(test_full_dataloader))['output'],teacher_forcing_ratio=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f170791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(preds, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21847800",
   "metadata": {},
   "source": [
    "# Utils To view the words\n",
    "\n",
    "Pass predictions.transpose(0,1)\n",
    "\n",
    "Pass batch['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea89dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb3f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_torchies(torchie1,index_toalp):\n",
    "    torchie=torchie1.cpu().numpy()\n",
    "    return word_from_vecs(torchie,index_toalp,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b064da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_hindi_alphabet))\n",
    "    return wordlet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d3d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch_eng(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_english_alphabet))\n",
    "    return wordlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8373ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=word_from_batch(predicted.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d86d544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual=word_from_batch(next(iter(test_full_dataloader))['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "133d2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input=word_from_batch_eng(next(iter(test_full_dataloader))['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51e2b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view in table form\n",
    "import pandas as pd\n",
    "datas={'Ground truth':test_actual,'Predictions':test_preds,}\n",
    "df=pd.DataFrame(data=datas,index=test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07e62ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct=df[df['Ground truth']==df['Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd5fde00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sikhaaega</th>\n",
       "      <td>सिखाएगा</td>\n",
       "      <td>सिखाएगा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitters</th>\n",
       "      <td>ट्विटर्स</td>\n",
       "      <td>ट्विटर्स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tirunelveli</th>\n",
       "      <td>तिरुनेलवेली</td>\n",
       "      <td>तिरुनेलवेली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>independence</th>\n",
       "      <td>इंडिपेंडेंस</td>\n",
       "      <td>इंडिपेंडेंस</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speshiyon</th>\n",
       "      <td>स्पेशियों</td>\n",
       "      <td>स्पेशियों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seho</th>\n",
       "      <td>सेहो</td>\n",
       "      <td>सेहो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belcha</th>\n",
       "      <td>बेलचा</td>\n",
       "      <td>बेलचा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shbana</th>\n",
       "      <td>शबाना</td>\n",
       "      <td>शबाना</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khaatootolaa</th>\n",
       "      <td>खातूटोला</td>\n",
       "      <td>खातूटोला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preranapuree</th>\n",
       "      <td>प्रेरणापुरी</td>\n",
       "      <td>प्रेरणापुरी</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1648 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ground truth  Predictions\n",
       "sikhaaega         सिखाएगा      सिखाएगा\n",
       "twitters         ट्विटर्स     ट्विटर्स\n",
       "tirunelveli   तिरुनेलवेली  तिरुनेलवेली\n",
       "independence  इंडिपेंडेंस  इंडिपेंडेंस\n",
       "speshiyon       स्पेशियों    स्पेशियों\n",
       "...                   ...          ...\n",
       "seho                 सेहो         सेहो\n",
       "belcha              बेलचा        बेलचा\n",
       "shbana              शबाना        शबाना\n",
       "khaatootolaa     खातूटोला     खातूटोला\n",
       "preranapuree  प्रेरणापुरी  प्रेरणापुरी\n",
       "\n",
       "[1648 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a885e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect=df[df['Ground truth']!=df['Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e3e8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['शिवास्तवा']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df_incorrect.iloc[-1]['Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38a8d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(df_incorrect.iloc[-5]['Predictions'],df_incorrect.iloc[-5]['Ground truth']):\n",
    "    print(i==j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85a5039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['अ', 'फ', 'स', 'र', 'ो', 'ं']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*df_incorrect.iloc[-5]['Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2d2e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['अ', 'फ', 'स', 'र', 'ा', 'े', 'ं']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*df_incorrect.iloc[-5]['Ground truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e574bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अफसराें'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incorrect.iloc[-5]['Ground truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5f3b886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>लर्न</td>\n",
       "      <td>लीरन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shurooh</th>\n",
       "      <td>शुरूः</td>\n",
       "      <td>शुरूह</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajhar</th>\n",
       "      <td>अजहर</td>\n",
       "      <td>अझर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karaar</th>\n",
       "      <td>क़रार</td>\n",
       "      <td>करार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anka</th>\n",
       "      <td>अंक</td>\n",
       "      <td>एएनकका</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aphasaron</th>\n",
       "      <td>अफसराें</td>\n",
       "      <td>अफसरों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chabate</th>\n",
       "      <td>चबाते</td>\n",
       "      <td>चबते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miti</th>\n",
       "      <td>मिति</td>\n",
       "      <td>मिटी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saflata</th>\n",
       "      <td>सफ़लता</td>\n",
       "      <td>सफलता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shivastava</th>\n",
       "      <td>शिवास्तव</td>\n",
       "      <td>शिवास्तवा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2447 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ground truth Predictions\n",
       "learn              लर्न        लीरन\n",
       "shurooh           शुरूः       शुरूह\n",
       "ajhar              अजहर         अझर\n",
       "karaar            क़रार        करार\n",
       "anka                अंक      एएनकका\n",
       "...                 ...         ...\n",
       "aphasaron       अफसराें      अफसरों\n",
       "chabate           चबाते        चबते\n",
       "miti               मिति        मिटी\n",
       "saflata          सफ़लता       सफलता\n",
       "shivastava     शिवास्तव   शिवास्तवा\n",
       "\n",
       "[2447 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
