{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323a4b37",
   "metadata": {},
   "source": [
    "# Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40aef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_english_alphabet=pickle.load(open('vocab_tools/index_to_english_alphabet.pickle', 'rb'))\n",
    "index_to_hindi_alphabet=pickle.load(open('vocab_tools/index_to_hindi_alphabet.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bc19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabet_to_index=pickle.load(open('vocab_tools/hindi_alphabet_to_index.pickle', 'rb')) \n",
    "english_alphabet_to_index=pickle.load(open('vocab_tools/english_alphabet_to_index.pickle', 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('simple_data/X_train.npy')\n",
    "X_valid=np.load('simple_data/X_val.npy')\n",
    "\n",
    "y_train=np.load('simple_data/y_train.npy')\n",
    "y_valid=np.load('simple_data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bb32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580946cf",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e291758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng_Hind_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, in_file, out_file, root_dir='simple_data',device='cuda'):\n",
    "\n",
    "        self.input = torch.tensor(np.load(root_dir+'/'+in_file))\n",
    "        self.output = torch.tensor(np.load(root_dir+'/'+out_file))\n",
    "        \n",
    "        assert(len(self.input)==len(self.output),\"Error: I/O Lengths must be same\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        X=self.input[idx]\n",
    "        X=X.to(device)\n",
    "        y=self.output[idx]\n",
    "        y=y.to(device)\n",
    "        \n",
    "\n",
    "\n",
    "        sample = {'input': X, 'output': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d715496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6f5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=Eng_Hind_Dataset(\"X_train.npy\",\"y_train.npy\",device=device)\n",
    "val_data=Eng_Hind_Dataset(\"X_val.npy\",\"y_val.npy\",device=device)\n",
    "test_data=Eng_Hind_Dataset(\"X_test.npy\",\"y_test.npy\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9249f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sets = torch.utils.data.ConcatDataset([training_data, val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b576ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataloader = DataLoader(train_val_sets, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53944bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d97754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e383a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_type(mode:str='rnn'):\n",
    "    mode=mode.lower()\n",
    "    if mode == 'rnn':\n",
    "        return nn.RNN\n",
    "    elif mode =='gru':\n",
    "        return nn.GRU\n",
    "    else:\n",
    "        return nn.LSTM\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b3ffd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e094b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder module of the Seq2Seq model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : int\n",
    "        Input size, should equal to the source vocabulary size.\n",
    "\n",
    "    embed_size : int\n",
    "        Embedding layer's dimension.\n",
    "\n",
    "    enc_hid_size : int\n",
    "        Encoder's hidden state size.\n",
    "\n",
    "    dec_hid_size : int\n",
    "        Decoder's hidden state size.\n",
    "\n",
    "    num_layers : int\n",
    "        Number of encoder layers.\n",
    "\n",
    "    cell_mode : str\n",
    "        Type of cell: LSTM, GRU, or RNN.\n",
    "\n",
    "    dropout : float\n",
    "        Dropout for the encoder layer.\n",
    "\n",
    "    is_bi : bool\n",
    "        Flag indicating if the encoder is bidirectional.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    embedding : nn.Embedding\n",
    "        Embedding layer.\n",
    "\n",
    "    cell : nn.Module\n",
    "        LSTM/GRU/RNN cell.\n",
    "\n",
    "    cell_mode : str\n",
    "        Type of cell: LSTM, GRU, or RNN.\n",
    "\n",
    "    is_bi : bool\n",
    "        Flag indicating if the encoder is bidirectional.\n",
    "\n",
    "    fc : nn.Linear\n",
    "        Linear layer to transform the encoder's hidden state.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_batch: torch.LongTensor)\n",
    "        Forward pass of the encoder.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, embed_size, enc_hid_size, dec_hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=english_alphabet_to_index['.'])\n",
    "\n",
    "        cell = cell_type(cell_mode)\n",
    "\n",
    "        self.cell = cell(embed_size, enc_hid_size, num_layers, dropout=dropout, bidirectional=is_bi, batch_first=True)\n",
    "        self.cell_mode = cell_mode\n",
    "        self.is_bi = is_bi\n",
    "        if is_bi:\n",
    "            self.fc = nn.Linear(enc_hid_size * 2, dec_hid_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(enc_hid_size, dec_hid_size)\n",
    "\n",
    "    def forward(self, input_batch: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_batch : torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [sent len, batch size].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : torch.Tensor\n",
    "            Outputs of the LSTM layer.\n",
    "\n",
    "        hidden : torch.Tensor\n",
    "            Hidden state of the LSTM layer.\n",
    "\n",
    "        cell : torch.Tensor (only for LSTM)\n",
    "            Cell state of the LSTM layer.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_batch)\n",
    "\n",
    "        if self.cell_mode.lower() == 'lstm':\n",
    "            outputs, (hidden, cell) = self.cell(embedded)\n",
    "\n",
    "            if self.is_bi:\n",
    "                concated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "                cellconcat = torch.cat((cell[-2, :, :], cell[-1, :, :]), dim=1)\n",
    "            else:\n",
    "                concated = hidden[-1, :, :]\n",
    "                cellconcat = cell[-1, :, :]\n",
    "\n",
    "            hidden = torch.tanh(self.fc(concated))\n",
    "            cell = torch.tanh(self.fc(cellconcat))\n",
    "\n",
    "            return outputs, hidden, cell\n",
    "\n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded)\n",
    "            if self.is_bi:\n",
    "                concated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "            else:\n",
    "                concated = hidden[-1, :, :]\n",
    "\n",
    "            hidden = torch.tanh(self.fc(concated))\n",
    "\n",
    "            return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e5c009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention module of the Seq2Seq model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    enc_hid_dim : int\n",
    "        Encoder's hidden state size.\n",
    "\n",
    "    dec_hid_dim : int\n",
    "        Decoder's hidden state size.\n",
    "\n",
    "    is_bi : bool\n",
    "        Flag indicating if the encoder is bidirectional.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    enc_hid_dim : int\n",
    "        Encoder's hidden state size.\n",
    "\n",
    "    dec_hid_dim : int\n",
    "        Decoder's hidden state size.\n",
    "\n",
    "    fc1 : nn.Linear\n",
    "        Linear layer to transform the concatenated input.\n",
    "\n",
    "    fc2 : nn.Linear\n",
    "        Linear layer to transform the attention energy.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(encoder_outputs, hidden)\n",
    "        Forward pass of the attention module.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim, is_bi):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        if is_bi:\n",
    "            self.fc1 = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n",
    "\n",
    "        self.fc2 = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the attention module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoder_outputs : torch.Tensor\n",
    "            Outputs of the encoder. Shape [batch size, src len, enc hid dim * num directions].\n",
    "\n",
    "        hidden : torch.Tensor\n",
    "            Hidden state of the decoder. Shape [batch size, dec hid dim].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        attention_weight : torch.Tensor\n",
    "            Attention weights. Shape [batch size, src len].\n",
    "\n",
    "        \"\"\"\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        outputs = encoder_outputs\n",
    "\n",
    "        concat = torch.cat((hidden, outputs), dim=2)\n",
    "        energy = torch.tanh(self.fc1(concat))\n",
    "\n",
    "        attention = self.fc2(energy).squeeze(dim=2)\n",
    "        attention_weight = torch.softmax(attention, dim=1)\n",
    "        return attention_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d1ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder module of the Seq2Seq model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_size : int\n",
    "        Size of the target vocabulary.\n",
    "\n",
    "    embed_size : int\n",
    "        Embedding layer's dimension.\n",
    "\n",
    "    enc_hid_dim : int\n",
    "        Encoder's hidden state size.\n",
    "\n",
    "    dec_hid_dim : int\n",
    "        Decoder's hidden state size.\n",
    "\n",
    "    num_layers : int\n",
    "        Number of layers in the decoder.\n",
    "\n",
    "    cell_mode : str\n",
    "        Cell type for the decoder (e.g., LSTM, GRU, RNN).\n",
    "\n",
    "    dropout : float\n",
    "        Dropout probability for the decoder.\n",
    "\n",
    "    attention : Attention\n",
    "        Attention module used by the decoder.\n",
    "\n",
    "    is_bi : bool\n",
    "        Flag indicating if the encoder is bidirectional.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dropout : float\n",
    "        Dropout probability for the decoder.\n",
    "\n",
    "    attention : Attention\n",
    "        Attention module used by the decoder.\n",
    "\n",
    "    output_size : int\n",
    "        Size of the target vocabulary.\n",
    "\n",
    "    embedding : nn.Embedding\n",
    "        Embedding layer.\n",
    "\n",
    "    cell : nn.Module\n",
    "        Decoder's LSTM/GRU/RNN cell.\n",
    "\n",
    "    out : nn.Linear\n",
    "        Linear layer to transform the decoder's output.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(trg, encoder_outputs, hidden, cell=None)\n",
    "        Forward pass of the decoder.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size, embed_size, enc_hid_dim, dec_hid_dim, num_layers, cell_mode, dropout, attention, is_bi):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=hindi_alphabet_to_index['.'])\n",
    "        cell = cell_type(cell_mode)\n",
    "        self.cell_mode = cell_mode.lower()\n",
    "\n",
    "        if is_bi:\n",
    "            self.cell = cell((enc_hid_dim * 2) + embed_size, dec_hid_dim, num_layers, dropout=dropout, bidirectional=False, batch_first=False)\n",
    "        else:\n",
    "            self.cell = cell(enc_hid_dim + embed_size, dec_hid_dim, num_layers, dropout=dropout, bidirectional=False, batch_first=False)\n",
    "\n",
    "        self.out = nn.Linear(dec_hid_dim, output_size)\n",
    "\n",
    "    def forward(self, trg, encoder_outputs, hidden, cell=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trg : torch.Tensor\n",
    "            Target tensor for a single time step. \n",
    "\n",
    "        encoder_outputs : torch.Tensor\n",
    "            Outputs of the encoder. \n",
    "\n",
    "        hidden : torch.Tensor\n",
    "            Hidden state of the decoder.\n",
    "\n",
    "        cell : torch.Tensor, optional\n",
    "            Cell state of the decoder for LSTM. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction : torch.Tensor\n",
    "            Output prediction for a single time step. \n",
    "\n",
    "        hidden : torch.Tensor\n",
    "            Hidden state of the decoder. \n",
    "\n",
    "        cell : torch.Tensor, optional\n",
    "            Cell state of the decoder for LSTM. \n",
    "\n",
    "        \"\"\"\n",
    "        attention = self.attention(encoder_outputs, hidden).unsqueeze(1)\n",
    "        context = torch.bmm(attention, encoder_outputs).permute(1, 0, 2)\n",
    "\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        cell_input = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        if self.cell_mode == 'lstm':\n",
    "            outputs, (hidden, cell) = self.cell(cell_input, (hidden.unsqueeze(0), cell.unsqueeze(0)))\n",
    "            prediction = self.out(outputs.squeeze(0))\n",
    "            return prediction, hidden.squeeze(0), cell.squeeze(0)\n",
    "\n",
    "        outputs, hidden = self.cell(cell_input, hidden.unsqueeze(0))\n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e441d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq model that combines an encoder and a decoder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoder : Encoder\n",
    "        Encoder module.\n",
    "\n",
    "    decoder : Decoder\n",
    "        Decoder module.\n",
    "\n",
    "    device : torch.device\n",
    "        Device to run the model on.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    encoder : Encoder\n",
    "        Encoder module.\n",
    "\n",
    "    decoder : Decoder\n",
    "        Decoder module.\n",
    "\n",
    "    device : torch.device\n",
    "        Device to run the model on.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(source_batch, target_batch, teacher_forcing_ratio=0.5)\n",
    "        Forward pass of the Seq2Seq model.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source_batch, target_batch, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Forward pass of the Seq2Seq model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source_batch : torch.Tensor\n",
    "            Input source sequences. Shape [batch size, source length].\n",
    "\n",
    "        target_batch : torch.Tensor\n",
    "            Target sequences. Shape [batch size, target length].\n",
    "\n",
    "        teacher_forcing_ratio : float, optional\n",
    "            The probability of using teacher forcing during training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : torch.Tensor\n",
    "            Decoder outputs for each time step. Shape [target length, batch size, target vocab size].\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size, max_len = target_batch.shape\n",
    "        target_vocab_size = self.decoder.output_size\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "        if self.encoder.cell_mode == 'lstm':\n",
    "            encoder_outputs, hidden, cell = self.encoder(source_batch)\n",
    "\n",
    "            trg = target_batch[:, 0]\n",
    "            for i in range(1, max_len):\n",
    "                prediction, hidden, cell = self.decoder(trg, encoder_outputs, hidden, cell)\n",
    "                outputs[i] = prediction\n",
    "\n",
    "                if np.random.random() < teacher_forcing_ratio:\n",
    "                    trg = target_batch[:, i]\n",
    "                else:\n",
    "                    trg = prediction.argmax(1)\n",
    "\n",
    "            return outputs\n",
    "\n",
    "        else:\n",
    "            encoder_outputs, hidden = self.encoder(source_batch)\n",
    "\n",
    "            trg = target_batch[:, 0]\n",
    "            for i in range(1, max_len):\n",
    "                prediction, hidden = self.decoder(trg, encoder_outputs, hidden)\n",
    "                outputs[i] = prediction\n",
    "\n",
    "                if np.random.random() < teacher_forcing_ratio:\n",
    "                    trg = target_batch[:, i]\n",
    "                else:\n",
    "                    trg = prediction.argmax(1)\n",
    "\n",
    "            return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f6133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(target_seq,seq2,mode='full',device=device):# predicted\n",
    "    eos_index=(target_seq==hindi_alphabet_to_index['>']).nonzero()\n",
    "    eos_idx=eos_index[:,1]\n",
    "    \n",
    "    correct=torch.Tensor([0]).to(device)\n",
    "    correct_chars=torch.Tensor([0]).to(device)\n",
    "    tot_chars=torch.Tensor([0]).to(device)\n",
    "    for iterate,idx in enumerate(eos_idx):\n",
    "        inputter=seq2[iterate][:idx]\n",
    "        outputter=target_seq[iterate][:idx]\n",
    "        if torch.all(torch.eq(inputter,outputter)):\n",
    "            correct+=1\n",
    "            correct_chars+=idx\n",
    "            tot_chars+=idx\n",
    "        else:\n",
    "            correct_chars+=torch.sum(inputter == outputter).item()\n",
    "            tot_chars+=idx\n",
    "            \n",
    "#         print(correct,correct_chars,tot_chars)\n",
    "        \n",
    "    return correct.item(),correct_chars.item(),tot_chars.item()\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87facdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    \n",
    "    \n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch['input'], batch['output'])\n",
    "        batch_label=batch['output'].transpose(0,1)\n",
    "        batch_size=len(batch['output'])\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=2)\n",
    "        outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch_label.reshape(-1)\n",
    "        \n",
    "\n",
    "        trg_flatten.requires_grad=False\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "        #___________\n",
    "        \n",
    "        correct+=correct_temp\n",
    "        correct_char+=correct_chars_temp\n",
    "        tot_char+=tot_chars_temp\n",
    "        \n",
    "        \n",
    "        #_______________\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a950559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            outputs = seq2seq(batch['input'], batch['output'],teacher_forcing_ratio=0)\n",
    "            batch_label=batch['output'].transpose(0,1)\n",
    "            batch_size=len(batch['output'])\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=2)\n",
    "            #print('wow_preds',predicted.shape)\n",
    "\n",
    "            outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "            trg_flatten = batch_label.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            \n",
    "            correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "            #___________\n",
    "\n",
    "            correct+=correct_temp\n",
    "            correct_char+=correct_chars_temp\n",
    "            tot_char+=tot_chars_temp\n",
    "\n",
    "            #_______________       \n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718d4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    e_time = end_time - start_time\n",
    "    mins = e_time // 60\n",
    "    secs = e_time%60\n",
    "    return mins, secs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eb08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d74d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd5bae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def make_model(train_iterator,valid_iterator, enc_embed_size, enc_hid_size, dec_embed_size, dec_hid_size,\\\n",
    "               num_layers, cell_mode,\\\n",
    "                 dropout, is_bi, epochs=20):\n",
    "    \n",
    "    \n",
    "    E = Encoder(30,  embed_size=enc_embed_size, enc_hid_size=enc_hid_size, dec_hid_size=dec_hid_size,\\\n",
    "                num_layers=num_layers, cell_mode=cell_mode, dropout=dropout, is_bi=is_bi).to(device)\n",
    "    \n",
    "    \n",
    "    A = Attention(enc_hid_dim=enc_hid_size, dec_hid_dim=dec_hid_size, is_bi=is_bi).to(device)\n",
    "\n",
    "    D = Decoder(68, embed_size=dec_embed_size, enc_hid_dim=enc_hid_size, dec_hid_dim=dec_hid_size,\\\n",
    "                num_layers=1, cell_mode=cell_mode,\\\n",
    "                 dropout=dropout, attention=A, is_bi=is_bi).to(device)\n",
    "\n",
    "    S=Seq2Seq(E,D,device)\n",
    "    S.to(device)    \n",
    "    print(f'The model has {count_params(S):,} trainable parameters')\n",
    "    \n",
    "    optimizer = optim.Adam(S.parameters())\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hindi_alphabet_to_index['.'])\n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "#     return S\n",
    "\n",
    "    for epoch in range(epochs):    \n",
    "        start_time = time.time()\n",
    "        train_loss,train_acc,train_stuff = train(S, train_iterator, optimizer, criterion)\n",
    "        valid_loss,valid_acc,val_stuff = evaluate(S, valid_iterator, criterion)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(S.state_dict(), 'model1.pt')\n",
    "\n",
    "        # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "        # of the loss, hence the scale of the measure is much bigger\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s')\n",
    "        print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print(f'\\t Relaxed Train. Acc: {train_stuff*100:.2f}% | Relaxed Val. Acc: {val_stuff*100:.2f}%')\n",
    "        \n",
    "        \n",
    "    return S\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48892180",
   "metadata": {},
   "source": [
    "# Make custom model \n",
    "pass your data loaders, configurations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbb83dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=train_val_dataloader\n",
    "valid_iterator=test_dataloader\n",
    "SS=make_model(train_iterator,valid_iterator,cell_mode='lstm',dec_embed_size=16,dec_hid_size=128,\\\n",
    "              dropout=0.2,enc_embed_size=32,enc_hid_size=256,epochs=30,is_bi=True,num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae99ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to Save Model\n",
    "\n",
    "# torch.save(SS, 'attn_model.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a446395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to laod model:\n",
    "\n",
    "# the_model = torch.load('attn_model.model')\n",
    "the_model=SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452339cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_dataloader = DataLoader(test_data, batch_size=len(test_data),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e79ef338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run on test data\n",
    "\n",
    "the_model.eval()\n",
    "preds=the_model(next(iter(test_full_dataloader))['input'],next(iter(test_full_dataloader))['output'],teacher_forcing_ratio=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f170791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(preds, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b064da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_hindi_alphabet))\n",
    "    return wordlet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6547dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch_eng(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_english_alphabet))\n",
    "    return wordlet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aac85d",
   "metadata": {},
   "source": [
    "# Utils To view the words\n",
    "\n",
    "Pass predictions.transpose(0,1)\n",
    "\n",
    "Pass batch['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea89dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb3f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_torchies(torchie1,index_toalp):\n",
    "    torchie=torchie1.cpu().numpy()\n",
    "    return word_from_vecs(torchie,index_toalp,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa47ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_hindi_alphabet))\n",
    "    return wordlet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d3d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch_eng(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_english_alphabet))\n",
    "    return wordlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8373ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=word_from_batch(predicted.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d86d544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual=word_from_batch(next(iter(test_full_dataloader))['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "133d2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input=word_from_batch_eng(next(iter(test_full_dataloader))['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "315277b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=word_from_batch(predicted.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "51e2b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datas={'Ground truth':test_actual,'Predictions Attention':test_preds, \"Predictions Vanilla\":va}\n",
    "df=pd.DataFrame(data=datas,index=test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a4c59b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=df[df['Predictions Attention']!=df['Predictions Vanilla']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "66aa5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=xx[xx['Predictions Attention']==xx['Ground truth']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cca9d1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions Attention</th>\n",
       "      <th>Predictions Vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shikayatkarta</th>\n",
       "      <td>शिकायतकर्ता</td>\n",
       "      <td>शिकायतकर्ता</td>\n",
       "      <td>शिकटयाकर्ता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaarniyaan</th>\n",
       "      <td>कार्नियां</td>\n",
       "      <td>कार्नियां</td>\n",
       "      <td>कारनियाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holt</th>\n",
       "      <td>होल्ट</td>\n",
       "      <td>होल्ट</td>\n",
       "      <td>हॉल्ट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laigikata</th>\n",
       "      <td>लैंगिकता</td>\n",
       "      <td>लैंगिकता</td>\n",
       "      <td>लैईगीकता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vankshetra</th>\n",
       "      <td>वनक्षेत्र</td>\n",
       "      <td>वनक्षेत्र</td>\n",
       "      <td>वंक्षेत्र</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>francisco</th>\n",
       "      <td>फ्रांसिस्को</td>\n",
       "      <td>फ्रांसिस्को</td>\n",
       "      <td>फ्रैंसिस्को</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raghavan</th>\n",
       "      <td>राघवन</td>\n",
       "      <td>राघवन</td>\n",
       "      <td>रघवन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thaki</th>\n",
       "      <td>थकी</td>\n",
       "      <td>थकी</td>\n",
       "      <td>ठकी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punchang</th>\n",
       "      <td>पंचांग</td>\n",
       "      <td>पंचांग</td>\n",
       "      <td>पुंचांग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khairati</th>\n",
       "      <td>खैराती</td>\n",
       "      <td>खैराती</td>\n",
       "      <td>खैरती</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ground truth Predictions Attention Predictions Vanilla\n",
       "shikayatkarta  शिकायतकर्ता           शिकायतकर्ता         शिकटयाकर्ता\n",
       "kaarniyaan       कार्नियां             कार्नियां            कारनियाँ\n",
       "holt                 होल्ट                 होल्ट               हॉल्ट\n",
       "laigikata         लैंगिकता              लैंगिकता            लैईगीकता\n",
       "vankshetra       वनक्षेत्र             वनक्षेत्र           वंक्षेत्र\n",
       "...                    ...                   ...                 ...\n",
       "francisco      फ्रांसिस्को           फ्रांसिस्को         फ्रैंसिस्को\n",
       "raghavan             राघवन                 राघवन                रघवन\n",
       "thaki                  थकी                   थकी                 ठकी\n",
       "punchang            पंचांग                पंचांग             पुंचांग\n",
       "khairati            खैराती                खैराती               खैरती\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "565a7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=xx[xx['Predictions Vanilla']==xx['Ground truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d7a85f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions Attention</th>\n",
       "      <th>Predictions Vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>twitters</th>\n",
       "      <td>ट्विटर्स</td>\n",
       "      <td>ट्वियरटर्स</td>\n",
       "      <td>ट्विटर्स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ukhrul</th>\n",
       "      <td>उखरुल</td>\n",
       "      <td>उखरूल</td>\n",
       "      <td>उखरुल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iqbal</th>\n",
       "      <td>इक़बाल</td>\n",
       "      <td>इकबाल</td>\n",
       "      <td>इक़बाल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umanath</th>\n",
       "      <td>उमानाथ</td>\n",
       "      <td>उमनाथ</td>\n",
       "      <td>उमानाथ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sushrushaa</th>\n",
       "      <td>सुश्रुषा</td>\n",
       "      <td>सुष्रशषा</td>\n",
       "      <td>सुश्रुषा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prapt</th>\n",
       "      <td>प्राप्त</td>\n",
       "      <td>प्रप्त</td>\n",
       "      <td>प्राप्त</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kanthahar</th>\n",
       "      <td>कंठहार</td>\n",
       "      <td>कंठहर</td>\n",
       "      <td>कंठहार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxide</th>\n",
       "      <td>ऑक्साइड</td>\n",
       "      <td>आक्साइड</td>\n",
       "      <td>ऑक्साइड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shbana</th>\n",
       "      <td>शबाना</td>\n",
       "      <td>श्बाना</td>\n",
       "      <td>शबाना</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khaatootolaa</th>\n",
       "      <td>खातूटोला</td>\n",
       "      <td>खातूतोला</td>\n",
       "      <td>खातूटोला</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ground truth Predictions Attention Predictions Vanilla\n",
       "twitters         ट्विटर्स            ट्वियरटर्स            ट्विटर्स\n",
       "ukhrul              उखरुल                 उखरूल               उखरुल\n",
       "iqbal              इक़बाल                 इकबाल              इक़बाल\n",
       "umanath            उमानाथ                 उमनाथ              उमानाथ\n",
       "sushrushaa       सुश्रुषा              सुष्रशषा            सुश्रुषा\n",
       "...                   ...                   ...                 ...\n",
       "prapt             प्राप्त                प्रप्त             प्राप्त\n",
       "kanthahar          कंठहार                 कंठहर              कंठहार\n",
       "oxide             ऑक्साइड               आक्साइड             ऑक्साइड\n",
       "shbana              शबाना                श्बाना               शबाना\n",
       "khaatootolaa     खातूटोला              खातूतोला            खातूटोला\n",
       "\n",
       "[385 rows x 3 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd5fde00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sikhaaega</th>\n",
       "      <td>सिखाएगा</td>\n",
       "      <td>सिखाएगा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tirunelveli</th>\n",
       "      <td>तिरुनेलवेली</td>\n",
       "      <td>तिरुनेलवेली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>independence</th>\n",
       "      <td>इंडिपेंडेंस</td>\n",
       "      <td>इंडिपेंडेंस</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speshiyon</th>\n",
       "      <td>स्पेशियों</td>\n",
       "      <td>स्पेशियों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kolhapur</th>\n",
       "      <td>कोल्हापुर</td>\n",
       "      <td>कोल्हापुर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khairati</th>\n",
       "      <td>खैराती</td>\n",
       "      <td>खैराती</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deshke</th>\n",
       "      <td>देशके</td>\n",
       "      <td>देशके</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seho</th>\n",
       "      <td>सेहो</td>\n",
       "      <td>सेहो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belcha</th>\n",
       "      <td>बेलचा</td>\n",
       "      <td>बेलचा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preranapuree</th>\n",
       "      <td>प्रेरणापुरी</td>\n",
       "      <td>प्रेरणापुरी</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ground truth  Predictions\n",
       "sikhaaega         सिखाएगा      सिखाएगा\n",
       "tirunelveli   तिरुनेलवेली  तिरुनेलवेली\n",
       "independence  इंडिपेंडेंस  इंडिपेंडेंस\n",
       "speshiyon       स्पेशियों    स्पेशियों\n",
       "kolhapur        कोल्हापुर    कोल्हापुर\n",
       "...                   ...          ...\n",
       "khairati           खैराती       खैराती\n",
       "deshke              देशके        देशके\n",
       "seho                 सेहो         सेहो\n",
       "belcha              बेलचा        बेलचा\n",
       "preranapuree  प्रेरणापुरी  प्रेरणापुरी\n",
       "\n",
       "[1739 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a885e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incorrect=df[df['Ground truth']!=df['Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f470e19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>लर्न</td>\n",
       "      <td>लियन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitters</th>\n",
       "      <td>ट्विटर्स</td>\n",
       "      <td>ट्वियरटर्स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shurooh</th>\n",
       "      <td>शुरूः</td>\n",
       "      <td>शुरूह</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajhar</th>\n",
       "      <td>अजहर</td>\n",
       "      <td>अझर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karaar</th>\n",
       "      <td>क़रार</td>\n",
       "      <td>करार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miti</th>\n",
       "      <td>मिति</td>\n",
       "      <td>मिटी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saflata</th>\n",
       "      <td>सफ़लता</td>\n",
       "      <td>सफलाता</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shbana</th>\n",
       "      <td>शबाना</td>\n",
       "      <td>श्बाना</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khaatootolaa</th>\n",
       "      <td>खातूटोला</td>\n",
       "      <td>खातूतोला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shivastava</th>\n",
       "      <td>शिवास्तव</td>\n",
       "      <td>शिवास्ता</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2356 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ground truth Predictions\n",
       "learn                लर्न        लियन\n",
       "twitters         ट्विटर्स  ट्वियरटर्स\n",
       "shurooh             शुरूः       शुरूह\n",
       "ajhar                अजहर         अझर\n",
       "karaar              क़रार        करार\n",
       "...                   ...         ...\n",
       "miti                 मिति        मिटी\n",
       "saflata            सफ़लता      सफलाता\n",
       "shbana              शबाना      श्बाना\n",
       "khaatootolaa     खातूटोला    खातूतोला\n",
       "shivastava       शिवास्तव    शिवास्ता\n",
       "\n",
       "[2356 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
