{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_english_alphabet=pickle.load(open('vocab_tools/index_to_english_alphabet.pickle', 'rb'))\n",
    "index_to_hindi_alphabet=pickle.load(open('vocab_tools/index_to_hindi_alphabet.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bc19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabet_to_index=pickle.load(open('vocab_tools/hindi_alphabet_to_index.pickle', 'rb')) \n",
    "english_alphabet_to_index=pickle.load(open('vocab_tools/english_alphabet_to_index.pickle', 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('simple_data/X_train.npy')\n",
    "X_valid=np.load('simple_data/X_val.npy')\n",
    "\n",
    "y_train=np.load('simple_data/y_train.npy')\n",
    "y_valid=np.load('simple_data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bb32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e291758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng_Hind_Dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, in_file, out_file, root_dir='simple_data',device='cuda'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.input = torch.tensor(np.load(root_dir+'/'+in_file))\n",
    "        self.output = torch.tensor(np.load(root_dir+'/'+out_file))\n",
    "        \n",
    "        assert(len(self.input)==len(self.output),\"Error: I/O Lengths must be same\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        X=self.input[idx]\n",
    "        X=X.to(device)\n",
    "        y=self.output[idx]\n",
    "        y=y.to(device)\n",
    "        \n",
    "\n",
    "\n",
    "        sample = {'input': X, 'output': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d715496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6f5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=Eng_Hind_Dataset(\"X_train.npy\",\"y_train.npy\",device=device)\n",
    "val_data=Eng_Hind_Dataset(\"X_val.npy\",\"y_val.npy\",device=device)\n",
    "test_data=Eng_Hind_Dataset(\"X_test.npy\",\"y_test.npy\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b576ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53944bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d97754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e383a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_type(mode:str='rnn'):\n",
    "    mode=mode.lower()\n",
    "    if mode == 'rnn':\n",
    "        return nn.RNN\n",
    "    elif mode =='gru':\n",
    "        return nn.GRU\n",
    "    else:\n",
    "        return nn.LSTM\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e094b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, input_size, embed_size, enc_hid_size, dec_hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, embed_size,padding_idx=english_alphabet_to_index['.'])\n",
    "\n",
    "        #creating LSTM/GRU/RNN cell\n",
    "        cell=cell_type(cell_mode)\n",
    "        \n",
    "        self.cell=cell(embed_size,enc_hid_size,num_layers,dropout=dropout,bidirectional=is_bi,batch_first=True)\n",
    "        self.cell_mode=cell_mode\n",
    "        self.is_bi=is_bi\n",
    "        if is_bi:\n",
    "            self.fc=nn.Linear(enc_hid_size*2, dec_hid_size)\n",
    "        else:\n",
    "            self.fc=nn.Linear(enc_hid_size, dec_hid_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_batch: torch.LongTensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        src_batch : 2d torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [sent len, batch size].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        hidden, cell : 3d torch.LongTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_batch) # [sent len, batch size, emb dim]\n",
    "        print('encoder embd',embedded.shape)\n",
    "        \n",
    "        if self.cell_mode.lower()=='lstm':\n",
    "            outputs, (hidden, cell) = self.cell(embedded)\n",
    "            if self.is_bi:\n",
    "                concated = torch.cat((hidden[ :,-2, :], hidden[ :,-1, :]), dim=1)\n",
    "                \n",
    "            else:\n",
    "                concated = hidden[ :,-1, :]\n",
    "                print(concated.shape)\n",
    "            \n",
    "            hidden = torch.tanh(self.fc(concated))\n",
    "            return outputs,hidden\n",
    "            \n",
    "            # return hidden, cell  \n",
    "        \n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded)\n",
    "            print('init_hidden', hidden.shape)\n",
    "            \n",
    "            print('hid',hidden[ :,-2, :].shape)\n",
    "            print('hiddd',hidden.shape)\n",
    "            \n",
    "            if self.is_bi:\n",
    "#                 concated = torch.cat((hidden[ :,-2, :], hidden[ :,-1, :]), dim=1)\n",
    "                concated = torch.cat((hidden[ -2, :,:], hidden[ -1, :,:]), dim=1)\n",
    "                print('oooo',concated.shape)\n",
    "                \n",
    "            else:\n",
    "                concated = hidden[ -1,:, :]\n",
    "                print(concated.shape)\n",
    "                \n",
    "            hidden = torch.tanh(self.fc(concated))\n",
    "            \n",
    "            return outputs,hidden\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcad189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9b15ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_alphabet_to_index['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c80f0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_s(nn.Module):\n",
    "    def __init__(self, output_size, embed_dim, hidden_size, num_layers, dropout,cell_type,attention):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type=cell_type\n",
    "        self.embedding = nn.Embedding(output_size, embed_dim,padding_idx=2)\n",
    "        if cell_type==\"LSTM\":\n",
    "          self.rnn = nn.LSTM((hidden_size*2)+embed_dim, hidden_size, num_layers,  dropout=dropout)\n",
    "        elif cell_type==\"GRU\":\n",
    "          self.rnn=nn.GRU((hidden_size*2)+embed_dim,hidden_size,num_layers,dropout=dropout,bidirectional=False)\n",
    "        else:\n",
    "          self.rnn=nn.RNN(hidden_size*2+embed_dim,hidden_size,num_layers,dropout=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.attention=attention\n",
    "        self.rnn\n",
    "\n",
    "    def forward(self, x,encoder_output,hidden,cell):\n",
    "        attention = self.attention(encoder_output, hidden).unsqueeze(1)\n",
    "#         output = encoder_output.permute(1, 0, 2)\n",
    "        output = encoder_output\n",
    "        print(attention.shape)\n",
    "        print(output.shape)\n",
    "        \n",
    "        context = torch.bmm(attention, output).permute(1, 0, 2)\n",
    "        print('att',attention.shape)\n",
    "        print('out',output.shape)\n",
    "        print('ctx',context.shape)\n",
    "        print('hid',hidden.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        if self.cell_type==\"LSTM\":\n",
    "          output,(hidden,cell) = self.rnn(rnn_input,(hidden.unsqueeze(0),cell.unsqueeze(0)))\n",
    "          output= self.fc(output.squeeze(0))\n",
    "          return output, hidden.squeeze(0),cell.squeeze(0)\n",
    "        \n",
    "        elif self.cell_type==\"GRU\":\n",
    "          output,hidden = self.rnn(rnn_input,hidden.unsqueeze(0))\n",
    "          output = output.squeeze(0)\n",
    "          output= self.fc(output)\n",
    "          return output, hidden.squeeze(0)\n",
    "        \n",
    "        else:\n",
    "          output,hidden = self.rnn(rnn_input,hidden.unsqueeze(0))\n",
    "          output = output.squeeze(0)\n",
    "          output= self.fc(output)\n",
    "          return output, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36d1ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_size, embed_size, enc_hid_dim, dec_hid_dim, num_layers, cell_mode,\\\n",
    "                 dropout, attention, is_bi):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embed_size,padding_idx=hindi_alphabet_to_index['.'])\n",
    "        cell=cell_type(cell_mode)\n",
    "        \n",
    "        \n",
    "        if is_bi:\n",
    "            self.cell=cell((enc_hid_dim * 2) + embed_size, dec_hid_dim,num_layers,\\\n",
    "                           dropout=dropout,bidirectional=False,batch_first=False)\n",
    "        \n",
    "\n",
    "        else:\n",
    "            self.cell=cell(enc_hid_dim + embed_size, dec_hid_dim,num_layers,\\\n",
    "                           dropout=dropout,bidirectional=False,batch_first=False)\n",
    "            \n",
    "        \n",
    "        \n",
    "        self.out = nn.Linear(dec_hid_dim, output_size)\n",
    "\n",
    "    def forward(self, trg, encoder_outputs, hidden):\n",
    " \n",
    "        attention = self.attention(encoder_outputs, hidden).unsqueeze(1)\n",
    "        print('att',attention.shape)\n",
    "        print('outs', encoder_outputs.shape)\n",
    "        \n",
    "        context = torch.bmm(attention, encoder_outputs).permute(1, 0, 2)\n",
    "\n",
    "        # input sentence -> embedding\n",
    "        # [1, batch size, emb dim]\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        print('emdb;,',embedded.shape)\n",
    "        print('contxt',context.shape)\n",
    "        cell_input = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        outputs, hidden = self.cell(cell_input, hidden.unsqueeze(0))\n",
    "        prediction = self.out(outputs.squeeze(0))\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2aa5bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder embd torch.Size([16, 30, 128])\n",
      "init_hidden torch.Size([2, 16, 128])\n",
      "hid torch.Size([2, 128])\n",
      "hiddd torch.Size([2, 16, 128])\n",
      "oooo torch.Size([16, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 30, 256]), torch.Size([16, 128]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# first experiment with n_layers = 1\n",
    "# input_size, embed_size, hid_size, dechid num_layers, cell_mode, dropout, is_bi\n",
    "encoder = Encoder(30, 128, 128, 128, 1, 'gru', 0.2, True).to(device)\n",
    "outputs, hidden = encoder(ss1['input'])\n",
    "outputs.shape, hidden.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebcb7f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:, -1, :128].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90620c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert (outputs[:, -1,:128] == hidden[2]).all()\n",
    "# assert (outputs[:,0, 128:] == hidden[3]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1aab272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn:outs torch.Size([16, 30, 256])\n",
      "attn:hid torch.Size([16, 30, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enc_hid_dim, dec_hid_dim, is_bi\n",
    "\n",
    "attention = Attention(128, 128, True).to(device)\n",
    "attention_weight = attention(outputs, hidden)\n",
    "attention_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4337531c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss1['output'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3008b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2643af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss1['output'][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19bd3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(68, 128, 128, 128, 1,'gru', 0.2, attention, False).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f77b553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (attention): Attention(\n",
       "    (fc1): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=1, bias=False)\n",
       "  )\n",
       "  (embedding): Embedding(68, 128, padding_idx=2)\n",
       "  (cell): GRU(256, 128, dropout=0.2)\n",
       "  (out): Linear(in_features=128, out_features=68, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e98f5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_alphabet_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e240e98e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Decoder_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoder_s\u001b[38;5;241m=\u001b[39m\u001b[43mDecoder_s\u001b[49m(\u001b[38;5;241m68\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU\u001b[39m\u001b[38;5;124m\"\u001b[39m,attention)\n\u001b[1;32m      2\u001b[0m decoder_s\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Decoder_s' is not defined"
     ]
    }
   ],
   "source": [
    "decoder_s=Decoder_s(68,128,128,1,0.1,\"GRU\",attention)\n",
    "decoder_s.to(device)\n",
    "# embed_dim, hidden_size, num_layers, dropout,cell_type,attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98735807",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_s\u001b[49m(ss1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m], outputs, hidden,\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# output_size, embed_size, enc_hid_dim, dec_hid_dim, num_layers, cell_mode, dropout, attention, is_bi\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# notice the decoder_hidden's shape should match the shape that's generated by\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# the encoder\u001b[39;00m\n\u001b[1;32m      5\u001b[0m prediction\u001b[38;5;241m.\u001b[39mshape, decoder_hidden\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_s' is not defined"
     ]
    }
   ],
   "source": [
    "prediction, decoder_hidden = decoder_s(ss1['output'][:,0], outputs, hidden,None)\n",
    "# output_size, embed_size, enc_hid_dim, dec_hid_dim, num_layers, cell_mode, dropout, attention, is_bi\n",
    "# notice the decoder_hidden's shape should match the shape that's generated by\n",
    "# the encoder\n",
    "prediction.shape, decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "407a195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.rnn.GRU'>\n",
      "attn:outs torch.Size([16, 30, 256])\n",
      "attn:hid torch.Size([16, 30, 128])\n",
      "att torch.Size([16, 1, 30])\n",
      "outs torch.Size([16, 30, 256])\n",
      "emdb;, torch.Size([1, 16, 128])\n",
      "contxt torch.Size([1, 16, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 68]), torch.Size([16, 128]))"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(68, 128, 128, 128, 1,'gru', 0.2, attention, False).to(device)\n",
    "prediction, decoder_hidden = decoder(ss1['output'][:,0], outputs, hidden)\n",
    "# output_size, embed_size, enc_hid_dim, dec_hid_dim, num_layers, cell_mode, dropout, attention, is_bi\n",
    "# notice the decoder_hidden's shape should match the shape that's generated by\n",
    "# the encoder\n",
    "prediction.shape, decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e5c009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim, is_bi):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        # enc_hid_dim multiply by 2 due to bidirectional\n",
    "        if is_bi:\n",
    "            self.fc1 = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "\n",
    "            \n",
    "            \n",
    "        self.fc2 = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        \n",
    "        # repeat encoder hidden state src_len times [batch size, sent len, dec hid dim]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # reshape/permute the encoder output, so that the batch size comes first\n",
    "        \n",
    "        # [batch size, sent len, enc hid dim * 2], times 2 because of bidirectional\n",
    "        # outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        outputs = encoder_outputs\n",
    "\n",
    "        # the attention mechanism receives a concatenation of the hidden state\n",
    "        # and the encoder output\n",
    "        print('attn:outs',outputs.shape)\n",
    "        print('attn:hid',hidden.shape)\n",
    "        concat = torch.cat((hidden, outputs), dim=2)\n",
    "        \n",
    "        # fully connected layer and softmax layer to compute the attention weight\n",
    "        # [batch size, sent len, dec hid dim]\n",
    "        energy = torch.tanh(self.fc1(concat))\n",
    "\n",
    "        # attention weight should be of [batch size, sent len]\n",
    "        attention = self.fc2(energy).squeeze(dim=2)        \n",
    "        attention_weight = torch.softmax(attention, dim=1)\n",
    "        return attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e441d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def forward(self, source_batch, target_batch, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        batch_size,max_len  = target_batch.shape\n",
    "        #print(max_len,batch_size)\n",
    "        target_vocab_size = self.decoder.output_size\n",
    "        #print(target_vocab_size)\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(source_batch)       \n",
    "\n",
    "        trg = target_batch[:,0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = target_batch[:,i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabet_to_index['>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(target_seq,seq2,mode='full',device=device):# predicted\n",
    "    eos_index=(target_seq==hindi_alphabet_to_index['>']).nonzero()\n",
    "    eos_idx=eos_index[:,1]\n",
    "    \n",
    "    correct=torch.Tensor([0]).to(device)\n",
    "    correct_chars=torch.Tensor([0]).to(device)\n",
    "    tot_chars=torch.Tensor([0]).to(device)\n",
    "    for iterate,idx in enumerate(eos_idx):\n",
    "        inputter=seq2[iterate][:idx]\n",
    "        outputter=target_seq[iterate][:idx]\n",
    "        if torch.all(torch.eq(inputter,outputter)):\n",
    "            correct+=1\n",
    "            correct_chars+=idx\n",
    "            tot_chars+=idx\n",
    "        else:\n",
    "            correct_chars+=torch.sum(inputter == outputter).item()\n",
    "            tot_chars+=idx\n",
    "            \n",
    "#         print(correct,correct_chars,tot_chars)\n",
    "        \n",
    "    return correct.item(),correct_chars.item(),tot_chars.item()\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee69981",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_calc(ss1['output'],ss1['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87facdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    \n",
    "    \n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch['input'], batch['output'])\n",
    "        batch_label=batch['output'].transpose(0,1)\n",
    "        batch_size=len(batch['output'])\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=2)\n",
    "        outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch_label.reshape(-1)\n",
    "        \n",
    "\n",
    "        trg_flatten.requires_grad=False\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "        #___________\n",
    "        \n",
    "        correct+=correct_temp\n",
    "        correct_char+=correct_chars_temp\n",
    "        tot_char+=tot_chars_temp\n",
    "        \n",
    "        \n",
    "        #_______________\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            outputs = seq2seq(batch['input'], batch['output'],teacher_forcing_ratio=0)\n",
    "            batch_label=batch['output'].transpose(0,1)\n",
    "            batch_size=len(batch['output'])\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=2)\n",
    "            #print('wow_preds',predicted.shape)\n",
    "\n",
    "            outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "            trg_flatten = batch_label.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            \n",
    "            correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "            #___________\n",
    "\n",
    "            correct+=correct_temp\n",
    "            correct_char+=correct_chars_temp\n",
    "            tot_char+=tot_chars_temp\n",
    "\n",
    "            #_______________       \n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    e_time = end_time - start_time\n",
    "    mins = e_time // 60\n",
    "    secs = e_time%60\n",
    "    return mins, secs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def make_model(train_iterator,valid_iterator,N_EPOCHS=20):\n",
    "    E=Encoder(30,128,128,2,'lstm',0.27,False)\n",
    "    E=E.to(device)\n",
    "    D=Decoder(68,128,128,2,'lstm',0.27,False)\n",
    "    D=D.to(device)\n",
    "    S=Seq2Seq(E,D,device)\n",
    "    S.to(device)    \n",
    "    print(f'The model has {count_params(S):,} trainable parameters')\n",
    "    \n",
    "    optimizer = optim.Adam(S.parameters())\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hindi_alphabet_to_index['.'])\n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "#     return S\n",
    "\n",
    "    for epoch in range(N_EPOCHS):    \n",
    "        start_time = time.time()\n",
    "        train_loss,train_acc,train_stuff = train(S, train_iterator, optimizer, criterion)\n",
    "        valid_loss,valid_acc,val_stuff = evaluate(S, valid_iterator, criterion)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(S.state_dict(), 'model1.pt')\n",
    "\n",
    "        # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "        # of the loss, hence the scale of the measure is much bigger\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s')\n",
    "        print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print(f'\\t Relaxed Train. Acc: {train_stuff*100:.2f}% | Relaxed Val. Acc: {val_stuff*100:.2f}%')\n",
    "        \n",
    "    return S\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ac096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=train_dataloader\n",
    "valid_iterator=val_dataloader\n",
    "SS=make_model(train_iterator,valid_iterator,N_EPOCHS=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya=SS(a['input'],a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5071c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_torchies(torchie1,index_toalp):\n",
    "    torchie=torchie1.cpu().numpy()\n",
    "    return word_from_vecs(torchie,index_toalp,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_hindi_alphabet))\n",
    "    return wordlet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_torchies(bya.transpose(0,1).argmax(2)[0],index_to_hindi_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_hindi_alphabet[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wrd(stuff):\n",
    "    asa=[]\n",
    "    for k in stuff.cpu().numpy():\n",
    "        asa.append(index_to_hindi_alphabet[k])\n",
    "    return \"\".join(asa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_wrd(bya.transpose(0,1).argmax(2)[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32caa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya.transpose(0,1).argmax(2)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print('................')\n",
    "    print(i)\n",
    "    print(word_from_torchies(a['output'][i],index_to_hindi_alphabet),\\\n",
    "         '---',\\\n",
    "         make_wrd(bya.transpose(0,1).argmax(2)[i])\\\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word (self, source_batch,target_batch):\n",
    "    max_len, batch_size = target_batch.shape\n",
    "    outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "\n",
    "            # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "    hidden, cell = self.encoder(source_batch)\n",
    "\n",
    "    wordet=[]\n",
    "\n",
    "\n",
    "    trg = torch.tensor(hindi_alphabet_to_index['<'])\n",
    "    trg=trg.to(device)\n",
    "    wordet.append(index_to_hindi_alphabet(trg.cpu().numpy()))\n",
    "    for i in range(1, max_len):\n",
    "        prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "        outputs[i] = prediction\n",
    "        trg = prediction.argmax(1)\n",
    "        wordet.append(index_to_hindi_alphabet(trg.cpu().numpy()))\n",
    "\n",
    "\n",
    "    return ''.join(wordet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ceca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_vecs(X_valid[0],index_to_english_alphabet,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_vecs(y_valid[0],index_to_hindi_alphabet,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc553c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b2342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "            for j in range(predicted.shape[1]):\n",
    "                predicted_seq = predicted[:, j]\n",
    "                targets_seq = target_seq[:, j]\n",
    "\n",
    "                # Find the index of the first EOS token in the sequence\n",
    "                eos_idx = (targets_seq == hin_token_map[\"\\n\"]).nonzero()\n",
    "                if eos_idx.numel() > 0:\n",
    "                    eos_idx = eos_idx[0][0]\n",
    "                    predicted_seq = predicted_seq[:eos_idx]\n",
    "                    targets_seq = targets_seq[:eos_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26653811",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
