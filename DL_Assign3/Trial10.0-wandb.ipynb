{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aef9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_english_alphabet=pickle.load(open('vocab_tools/index_to_english_alphabet.pickle', 'rb'))\n",
    "index_to_hindi_alphabet=pickle.load(open('vocab_tools/index_to_hindi_alphabet.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bc19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabet_to_index=pickle.load(open('vocab_tools/hindi_alphabet_to_index.pickle', 'rb')) \n",
    "english_alphabet_to_index=pickle.load(open('vocab_tools/english_alphabet_to_index.pickle', 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('simple_data/X_train.npy')\n",
    "X_valid=np.load('simple_data/X_val.npy')\n",
    "\n",
    "y_train=np.load('simple_data/y_train.npy')\n",
    "y_valid=np.load('simple_data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bb32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e291758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng_Hind_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, in_file, out_file, root_dir='simple_data',device='cuda'):\n",
    "\n",
    "        self.input = torch.tensor(np.load(root_dir+'/'+in_file))\n",
    "        self.output = torch.tensor(np.load(root_dir+'/'+out_file))\n",
    "        \n",
    "        assert(len(self.input)==len(self.output),\"Error: I/O Lengths must be same\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        X=self.input[idx]\n",
    "        X=X.to(device)\n",
    "        y=self.output[idx]\n",
    "        y=y.to(device)\n",
    "        \n",
    "\n",
    "\n",
    "        sample = {'input': X, 'output': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d715496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6f5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=Eng_Hind_Dataset(\"X_train.npy\",\"y_train.npy\",device=device)\n",
    "val_data=Eng_Hind_Dataset(\"X_val.npy\",\"y_val.npy\",device=device)\n",
    "test_data=Eng_Hind_Dataset(\"X_test.npy\",\"y_test.npy\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b576ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53944bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_data, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d97754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e383a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_type(mode:str='rnn'):\n",
    "    mode=mode.lower()\n",
    "    if mode == 'rnn':\n",
    "        return nn.RNN\n",
    "    elif mode =='gru':\n",
    "        return nn.GRU\n",
    "    else:\n",
    "        return nn.LSTM\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e094b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "        - source batch\n",
    "    Layer : \n",
    "        source batch -> Embedding -> LSTM\n",
    "    Output :\n",
    "        - LSTM hidden state\n",
    "        - LSTM cell state\n",
    "\n",
    "    Parmeters\n",
    "    ---------\n",
    "    input_dim : int\n",
    "        Input dimension, should equal to the source vocab size.\n",
    "    \n",
    "    emb_dim : int\n",
    "        Embedding layer's dimension.\n",
    "        \n",
    "    hid_dim : int\n",
    "        LSTM Hidden/Cell state's dimension.\n",
    "        \n",
    "    n_layers : int\n",
    "        Number of LSTM layers.\n",
    "        \n",
    "    dropout : float\n",
    "        Dropout for the LSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, enc_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, enc_embed_size,padding_idx=english_alphabet_to_index['.'])\n",
    "\n",
    "        #creating LSTM/GRU/RNN cell\n",
    "        cell=cell_type(cell_mode)\n",
    "        \n",
    "        self.cell=cell(enc_embed_size,hid_size,num_layers,dropout=dropout,bidirectional=is_bi,batch_first=True)\n",
    "        self.cell_mode=cell_mode\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_batch: torch.LongTensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        src_batch : 2d torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [sent len, batch size].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        hidden, cell : 3d torch.LongTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_batch) # [sent len, batch size, emb dim]\n",
    "        #print('encoder embd',embedded.shape)\n",
    "        \n",
    "        if self.cell_mode.lower()=='lstm':\n",
    "            outputs, (hidden, cell) = self.cell(embedded)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded)\n",
    "            cell=outputs\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761debd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "        - first token in the target batch\n",
    "        - LSTM hidden state from the encoder\n",
    "        - LSTM cell state from the encoder\n",
    "    Layer :\n",
    "        target batch -> Embedding -- \n",
    "                                   |\n",
    "        encoder hidden state ------|--> LSTM -> Linear\n",
    "                                   |\n",
    "        encoder cell state   -------\n",
    "        \n",
    "    Output :\n",
    "        - prediction\n",
    "        - LSTM hidden state\n",
    "        - LSTM cell state\n",
    "\n",
    "    Parmeters\n",
    "    ---------\n",
    "    output : int\n",
    "        Output dimension, should equal to the target vocab size.\n",
    "    \n",
    "    emb_dim : int\n",
    "        Embedding layer's dimension.\n",
    "        \n",
    "    hid_dim : int\n",
    "        LSTM Hidden/Cell state's dimension.\n",
    "        \n",
    "    n_layers : int\n",
    "        Number of LSTM layers.\n",
    "        \n",
    "    dropout : float\n",
    "        Dropout for the LSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, output_size, dec_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, dec_embed_size,padding_idx=hindi_alphabet_to_index['.'])\n",
    "        \n",
    "        cell=cell_type(cell_mode)\n",
    "        \n",
    "        self.cell=cell(dec_embed_size,hid_size,num_layers,dropout=dropout,bidirectional=is_bi,batch_first=True)\n",
    "        if is_bi:\n",
    "            self.out = nn.Linear(hid_size*2, output_size)\n",
    "        else:\n",
    "             self.out = nn.Linear(hid_size, output_size)\n",
    "        \n",
    "        self.output_size=output_size\n",
    "        self.cell_mode=cell_mode\n",
    "        \n",
    "\n",
    "    def forward(self, trg: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trg : 1d torch.LongTensor\n",
    "            Batched tokenized source sentence of shape [batch size].\n",
    "            \n",
    "        hidden, cell : 3d torch.FloatTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction : 2d torch.LongTensor\n",
    "            For each token in the batch, the predicted target vobulary.\n",
    "            Shape [batch size, output dim]\n",
    "\n",
    "        hidden, cell : 3d torch.FloatTensor\n",
    "            Hidden and cell state of the LSTM layer. Each state's shape\n",
    "            [n layers * n directions, batch size, hidden dim]\n",
    "        \"\"\"\n",
    "        # [1, batch size, emb dim], the 1 serves as sent len\n",
    "        embedded = self.embedding(trg.unsqueeze(1))\n",
    "        if self.cell_mode.lower()=='lstm':\n",
    "            #print('decoder embed',embedded.shape)\n",
    "            outputs, (hidden, cell) = self.cell(embedded, (hidden, cell))\n",
    "        else:\n",
    "            outputs, hidden = self.cell(embedded, hidden)\n",
    "            cell=hidden\n",
    "        prediction = self.out(outputs.squeeze(1))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e441d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def forward(self, source_batch, target_batch, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        batch_size,max_len  = target_batch.shape\n",
    "        #print(max_len,batch_size)\n",
    "        target_vocab_size = self.decoder.output_size\n",
    "        #print(target_vocab_size)\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "        hidden, cell = self.encoder(source_batch)       \n",
    "\n",
    "        trg = target_batch[:,0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if np.random.random() < teacher_forcing_ratio:\n",
    "                trg = target_batch[:,i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a7bf25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_alphabet_to_index['>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dcad189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a3bb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E=Encoder(30, embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "# E=E.to(device)\n",
    "\n",
    "# D=Decoder(68, embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "\n",
    "# D=D.to(device)\n",
    "# S=Seq2Seq(E,D,device)\n",
    "# S.to(device)    \n",
    "# print(f'The model has {count_params(S):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aff54c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(30, 64, padding_idx=2)\n",
       "    (cell): LSTM(64, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(68, 128, padding_idx=2)\n",
       "    (cell): LSTM(128, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=512, out_features=68, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=Encoder(30, 64, 256, 1, 'lstm', 0.1, True)\n",
    "E=E.to(device)\n",
    "\n",
    "D=Decoder(68, 128, 256, 1, 'lstm', 0.1, True)\n",
    "\n",
    "D=D.to(device)\n",
    "S=Seq2Seq(E,D,device)\n",
    "S.to(device)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00d8cf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 7.1363e-02,  1.9440e-02, -3.3042e-02,  ..., -2.0240e-02,\n",
       "          -1.6442e-03,  3.8942e-03],\n",
       "         [ 8.3536e-02,  2.1729e-03,  1.3374e-03,  ..., -8.2703e-03,\n",
       "          -1.7474e-02,  4.9452e-03],\n",
       "         [ 7.9245e-02,  2.0575e-03, -8.8284e-03,  ..., -1.2259e-02,\n",
       "          -2.4090e-02,  1.9068e-02],\n",
       "         ...,\n",
       "         [ 8.3514e-02, -9.8055e-03, -1.3272e-02,  ..., -1.0238e-03,\n",
       "          -2.0543e-03,  5.7374e-03],\n",
       "         [ 8.8629e-02,  8.4974e-03, -1.0090e-02,  ..., -7.1402e-03,\n",
       "          -1.8876e-02,  1.0042e-02],\n",
       "         [ 7.5774e-02,  1.0241e-02, -2.1955e-02,  ..., -1.6008e-02,\n",
       "          -1.0922e-03,  7.8834e-03]],\n",
       "\n",
       "        [[ 4.6290e-02,  9.8215e-03,  1.5137e-02,  ..., -1.5706e-02,\n",
       "          -3.6850e-04, -7.3477e-02],\n",
       "         [ 1.3339e-01, -6.8779e-02, -5.5854e-02,  ...,  1.1997e-02,\n",
       "           5.5819e-03, -7.1276e-02],\n",
       "         [-9.3163e-02, -6.6922e-02, -1.5923e-02,  ...,  5.5077e-02,\n",
       "           8.0446e-02,  3.5726e-02],\n",
       "         ...,\n",
       "         [ 2.7829e-02,  1.3597e-04,  7.6056e-02,  ..., -5.3649e-02,\n",
       "          -2.2465e-02,  4.0022e-02],\n",
       "         [ 2.9655e-02,  1.0718e-02,  7.9049e-02,  ..., -5.2445e-02,\n",
       "          -2.9063e-02,  3.9963e-02],\n",
       "         [ 4.8655e-02,  3.7330e-03,  2.3186e-02,  ..., -1.4905e-02,\n",
       "           1.9917e-03, -7.1150e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.3129e-01, -6.8116e-03,  6.4369e-02,  ...,  1.5029e-02,\n",
       "          -4.0284e-02,  1.2378e-02],\n",
       "         [-2.2648e-02, -1.5563e-03,  1.9615e-02,  ...,  1.0031e-01,\n",
       "           1.1712e-02,  1.4592e-01],\n",
       "         [ 1.3125e-01, -6.9959e-03,  6.4253e-02,  ...,  1.5021e-02,\n",
       "          -4.0302e-02,  1.2423e-02],\n",
       "         ...,\n",
       "         [ 1.3115e-01, -6.0040e-03,  6.6044e-02,  ...,  1.5897e-02,\n",
       "          -3.9563e-02,  1.3105e-02],\n",
       "         [ 1.3115e-01, -5.9896e-03,  6.6043e-02,  ...,  1.5875e-02,\n",
       "          -3.9643e-02,  1.3093e-02],\n",
       "         [ 1.3129e-01, -6.8118e-03,  6.4369e-02,  ...,  1.5029e-02,\n",
       "          -4.0284e-02,  1.2379e-02]],\n",
       "\n",
       "        [[ 4.0154e-02, -8.5739e-03, -9.9748e-03,  ..., -2.7720e-02,\n",
       "          -5.3514e-02, -7.5273e-02],\n",
       "         [ 3.3030e-02,  6.0781e-02, -5.2865e-02,  ...,  7.6411e-02,\n",
       "           5.5893e-02,  1.9407e-02],\n",
       "         [ 4.0116e-02, -8.6817e-03, -1.0030e-02,  ..., -2.7720e-02,\n",
       "          -5.3507e-02, -7.5280e-02],\n",
       "         ...,\n",
       "         [ 4.0091e-02, -8.5004e-03, -9.5077e-03,  ..., -2.7425e-02,\n",
       "          -5.3082e-02, -7.4779e-02],\n",
       "         [ 4.0092e-02, -8.5134e-03, -9.4861e-03,  ..., -2.7474e-02,\n",
       "          -5.3136e-02, -7.4797e-02],\n",
       "         [ 4.0155e-02, -8.5738e-03, -9.9753e-03,  ..., -2.7720e-02,\n",
       "          -5.3514e-02, -7.5273e-02]],\n",
       "\n",
       "        [[ 3.9231e-02, -2.4007e-03,  3.1394e-03,  ..., -1.6669e-02,\n",
       "          -2.3658e-02, -1.0412e-02],\n",
       "         [ 2.9107e-02,  3.5024e-02, -1.6199e-02,  ...,  5.9128e-02,\n",
       "           3.2844e-02,  3.2506e-02],\n",
       "         [ 3.9205e-02, -2.4754e-03,  3.1043e-03,  ..., -1.6666e-02,\n",
       "          -2.3647e-02, -1.0403e-02],\n",
       "         ...,\n",
       "         [ 3.8997e-02, -2.0859e-03,  3.5330e-03,  ..., -1.6281e-02,\n",
       "          -2.3315e-02, -1.0216e-02],\n",
       "         [ 3.9003e-02, -2.0916e-03,  3.5410e-03,  ..., -1.6301e-02,\n",
       "          -2.3357e-02, -1.0218e-02],\n",
       "         [ 3.9231e-02, -2.4017e-03,  3.1386e-03,  ..., -1.6668e-02,\n",
       "          -2.3659e-02, -1.0411e-02]]], device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S(ss1['input'],ss1['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(target_seq,seq2,mode='full',device=device):# predicted\n",
    "    eos_index=(target_seq==hindi_alphabet_to_index['>']).nonzero()\n",
    "    eos_idx=eos_index[:,1]\n",
    "    \n",
    "    correct=torch.Tensor([0]).to(device)\n",
    "    correct_chars=torch.Tensor([0]).to(device)\n",
    "    tot_chars=torch.Tensor([0]).to(device)\n",
    "    for iterate,idx in enumerate(eos_idx):\n",
    "        inputter=seq2[iterate][:idx]\n",
    "        outputter=target_seq[iterate][:idx]\n",
    "        if torch.all(torch.eq(inputter,outputter)):\n",
    "            correct+=1\n",
    "            correct_chars+=idx\n",
    "            tot_chars+=idx\n",
    "        else:\n",
    "            correct_chars+=torch.sum(inputter == outputter).item()\n",
    "            tot_chars+=idx\n",
    "            \n",
    "#         print(correct,correct_chars,tot_chars)\n",
    "        \n",
    "    return correct.item(),correct_chars.item(),tot_chars.item()\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ee69981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.0, 137.0, 137.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_calc(ss1['output'],ss1['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87facdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    \n",
    "    \n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch['input'], batch['output'])\n",
    "        batch_label=batch['output'].transpose(0,1)\n",
    "        batch_size=len(batch['output'])\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=2)\n",
    "        outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch_label.reshape(-1)\n",
    "        \n",
    "\n",
    "        trg_flatten.requires_grad=False\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "        #___________\n",
    "        \n",
    "        correct+=correct_temp\n",
    "        correct_char+=correct_chars_temp\n",
    "        tot_char+=tot_chars_temp\n",
    "        \n",
    "        \n",
    "        #_______________\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a950559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    correct_char=0\n",
    "    tot_char=0\n",
    "    \n",
    "    relax_acc=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            outputs = seq2seq(batch['input'], batch['output'],teacher_forcing_ratio=0)\n",
    "            batch_label=batch['output'].transpose(0,1)\n",
    "            batch_size=len(batch['output'])\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=2)\n",
    "            #print('wow_preds',predicted.shape)\n",
    "\n",
    "            outputs_flatten = outputs.view(-1, outputs.shape[-1])\n",
    "            trg_flatten = batch_label.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            \n",
    "            correct_temp,correct_chars_temp,tot_chars_temp=accuracy_calc(batch['output'],predicted.transpose(0,1))\n",
    "        \n",
    "            #___________\n",
    "\n",
    "            correct+=correct_temp\n",
    "            correct_char+=correct_chars_temp\n",
    "            tot_char+=tot_chars_temp\n",
    "\n",
    "            #_______________       \n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "\n",
    "    return epoch_loss / len(iterator), correct/(len(iterator)*16),correct_char/tot_char\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "718d4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    e_time = end_time - start_time\n",
    "    mins = e_time // 60\n",
    "    secs = e_time%60\n",
    "    return mins, secs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d74d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd5bae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def make_model(train_iterator,valid_iterator, enc_embed_size,dec_embed_size,\n",
    "               hid_size, num_layers, cell_mode, dropout, is_bi, epochs=20):\n",
    "    E=Encoder(30, enc_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "    E=E.to(device)\n",
    "    \n",
    "    D=Decoder(68, dec_embed_size, hid_size, num_layers, cell_mode, dropout, is_bi)\n",
    "    \n",
    "    D=D.to(device)\n",
    "    S=Seq2Seq(E,D,device)\n",
    "    S.to(device)    \n",
    "    print(f'The model has {count_params(S):,} trainable parameters')\n",
    "    \n",
    "    optimizer = optim.Adam(S.parameters())\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hindi_alphabet_to_index['.'])\n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):    \n",
    "        start_time = time.time()\n",
    "        train_loss,train_acc,train_stuff = train(S, train_iterator, optimizer, criterion)\n",
    "        valid_loss,valid_acc,val_stuff = evaluate(S, valid_iterator, criterion)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(S.state_dict(), 'model1.pt')\n",
    "\n",
    "        # it's easier to see a change in perplexity between epoch as it's an exponential\n",
    "        # of the loss, hence the scale of the measure is much bigger\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s')\n",
    "        print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        print(f'\\t Relaxed Train. Acc: {train_stuff*100:.2f}% | Relaxed Val. Acc: {val_stuff*100:.2f}%')\n",
    "        wandb.log({'epoch':epoch, 'train loss':train_loss, 'train acc':train_acc, 'valid loss': valid_loss,\n",
    "                  'valid acc': valid_acc, 'relxd train acc': train_stuff, 'relxd valid acc': val_stuff})\n",
    "        \n",
    "    return S\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1049df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator=train_dataloader\n",
    "# valid_iterator=val_dataloader\n",
    "# SS=make_model(train_iterator,valid_iterator,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b4a53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweeper():\n",
    "    \n",
    "    config_defaults=None\n",
    "    \n",
    "    \n",
    "    # Initialize new wandb run\n",
    "    run=wandb.init(config=config_defaults,resume=True)\n",
    "    #current config\n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    np.random.seed(0) #setting a seed to make better inference of use of params\n",
    "    \n",
    "    train_iterator=train_dataloader\n",
    "    valid_iterator=val_dataloader\n",
    "    SS=make_model(train_iterator,valid_iterator, config.enc_embed_size, config.dec_embed_size,\n",
    "               config.hid_size, config.num_layers, config.cell_mode, config.dropout, config.is_bi, config.epochs)\n",
    "    \n",
    "    run_name='Run:' +\\\n",
    "    ' enc_embed size: ' + str(config.enc_embed_size) +\\\n",
    "    ' dec_embed size: ' + str(config.dec_embed_size) +\\\n",
    "    ', hid_size: ' + str(config.hid_size) +\\\n",
    "    ', num_layers: ' + str(config.num_layers)+\\\n",
    "    ', cell_mode'+ str(config.cell_mode)\n",
    "    ', dropout:' + str(config.dropout)+\\\n",
    "    ', bidirect?:' + str(config.is_bi)+\\\n",
    "    ', epochs:'+str(config.epochs)+\\\n",
    "    ' simple.'\n",
    "    print(run_name)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()\n",
    "#     run.finalize()\n",
    "\n",
    "#     wandb.run.finish()\n",
    "#     run.finish()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f2e976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpragalbh\u001b[0m (\u001b[33mpragalbh-tushar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb3332e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"Simple sweep: No Attn\",\n",
    "  \"metric\": {\n",
    "      \"name\":\"valid acc\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"method\": \"bayes\",\n",
    "  \"parameters\": {\n",
    "              'num_layers':{\n",
    "                  \"values\":[1,2,3]\n",
    "              },\n",
    "        'enc_embed_size':{\n",
    "                \"values\":  [16,32, 64, 128, 256, 512]\n",
    "                  \n",
    "              },\n",
    "      'dec_embed_size':{\n",
    "                \"values\":  [16,32, 64, 128, 256, 512]\n",
    "                  \n",
    "              },\n",
    "        'hid_size':{\n",
    "            \"values\": [16,32, 64, 128, 256, 512]\n",
    "        },\n",
    "      \n",
    "        'cell_mode':{\n",
    "            'values': ['rnn','gru','lstm']\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0.2,0.25,0.3]\n",
    "        },\n",
    "        'is_bi': {\n",
    "            \"values\": [True, False]\n",
    "        },\n",
    "        'epochs': {\n",
    "            \"values\": [10, 20, 30, 40]\n",
    "        } ,\n",
    "        \n",
    "    }\n",
    "}      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "724ca19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config,  entity=\"pragalbh\", project=\"DL_Assign3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10cdce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rqo2cy6g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpragalbh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230525_220753-rqo2cy6g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/rqo2cy6g' target=\"_blank\">honest-sweep-34</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/rqo2cy6g' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/rqo2cy6g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 841,796 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 35.76s\n",
      "\t Train Loss: 2.734 | Train Acc: 0.21%\n",
      "\t Val. Loss: 2.161 |  Val. Acc: 5.42%\n",
      "\t Relaxed Train. Acc: 32.43% | Relaxed Val. Acc: 50.55%\n",
      "Epoch: 02 | Time: 0.0m 35.60s\n",
      "\t Train Loss: 1.758 | Train Acc: 5.26%\n",
      "\t Val. Loss: 1.708 |  Val. Acc: 16.06%\n",
      "\t Relaxed Train. Acc: 57.43% | Relaxed Val. Acc: 61.46%\n",
      "Epoch: 03 | Time: 0.0m 35.57s\n",
      "\t Train Loss: 1.483 | Train Acc: 10.91%\n",
      "\t Val. Loss: 1.609 |  Val. Acc: 20.02%\n",
      "\t Relaxed Train. Acc: 65.53% | Relaxed Val. Acc: 64.50%\n",
      "Epoch: 04 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 1.371 | Train Acc: 14.29%\n",
      "\t Val. Loss: 1.544 |  Val. Acc: 24.95%\n",
      "\t Relaxed Train. Acc: 68.95% | Relaxed Val. Acc: 67.93%\n",
      "Epoch: 05 | Time: 0.0m 35.67s\n",
      "\t Train Loss: 1.302 | Train Acc: 16.74%\n",
      "\t Val. Loss: 1.521 |  Val. Acc: 25.76%\n",
      "\t Relaxed Train. Acc: 71.16% | Relaxed Val. Acc: 68.30%\n",
      "Epoch: 06 | Time: 0.0m 35.65s\n",
      "\t Train Loss: 1.258 | Train Acc: 18.45%\n",
      "\t Val. Loss: 1.517 |  Val. Acc: 27.98%\n",
      "\t Relaxed Train. Acc: 72.55% | Relaxed Val. Acc: 68.77%\n",
      "Epoch: 07 | Time: 0.0m 35.72s\n",
      "\t Train Loss: 1.215 | Train Acc: 20.47%\n",
      "\t Val. Loss: 1.479 |  Val. Acc: 27.69%\n",
      "\t Relaxed Train. Acc: 73.97% | Relaxed Val. Acc: 69.84%\n",
      "Epoch: 08 | Time: 0.0m 35.79s\n",
      "\t Train Loss: 1.189 | Train Acc: 21.58%\n",
      "\t Val. Loss: 1.487 |  Val. Acc: 30.47%\n",
      "\t Relaxed Train. Acc: 74.78% | Relaxed Val. Acc: 70.71%\n",
      "Epoch: 09 | Time: 0.0m 35.79s\n",
      "\t Train Loss: 1.169 | Train Acc: 22.83%\n",
      "\t Val. Loss: 1.429 |  Val. Acc: 31.18%\n",
      "\t Relaxed Train. Acc: 75.44% | Relaxed Val. Acc: 71.55%\n",
      "Epoch: 10 | Time: 0.0m 35.77s\n",
      "\t Train Loss: 1.141 | Train Acc: 23.83%\n",
      "\t Val. Loss: 1.459 |  Val. Acc: 31.49%\n",
      "\t Relaxed Train. Acc: 76.32% | Relaxed Val. Acc: 71.10%\n",
      "Epoch: 11 | Time: 0.0m 35.76s\n",
      "\t Train Loss: 1.133 | Train Acc: 24.75%\n",
      "\t Val. Loss: 1.467 |  Val. Acc: 31.54%\n",
      "\t Relaxed Train. Acc: 76.66% | Relaxed Val. Acc: 70.92%\n",
      "Epoch: 12 | Time: 0.0m 35.76s\n",
      "\t Train Loss: 1.116 | Train Acc: 25.18%\n",
      "\t Val. Loss: 1.436 |  Val. Acc: 32.30%\n",
      "\t Relaxed Train. Acc: 77.13% | Relaxed Val. Acc: 72.18%\n",
      "Epoch: 13 | Time: 0.0m 35.75s\n",
      "\t Train Loss: 1.097 | Train Acc: 26.24%\n",
      "\t Val. Loss: 1.442 |  Val. Acc: 31.93%\n",
      "\t Relaxed Train. Acc: 77.84% | Relaxed Val. Acc: 71.61%\n",
      "Epoch: 14 | Time: 0.0m 35.74s\n",
      "\t Train Loss: 1.082 | Train Acc: 26.94%\n",
      "\t Val. Loss: 1.461 |  Val. Acc: 31.45%\n",
      "\t Relaxed Train. Acc: 78.33% | Relaxed Val. Acc: 71.77%\n",
      "Epoch: 15 | Time: 0.0m 35.73s\n",
      "\t Train Loss: 1.080 | Train Acc: 27.31%\n",
      "\t Val. Loss: 1.420 |  Val. Acc: 32.40%\n",
      "\t Relaxed Train. Acc: 78.39% | Relaxed Val. Acc: 72.31%\n",
      "Epoch: 16 | Time: 0.0m 35.74s\n",
      "\t Train Loss: 1.066 | Train Acc: 28.22%\n",
      "\t Val. Loss: 1.436 |  Val. Acc: 33.42%\n",
      "\t Relaxed Train. Acc: 78.80% | Relaxed Val. Acc: 72.49%\n",
      "Epoch: 17 | Time: 0.0m 35.72s\n",
      "\t Train Loss: 1.055 | Train Acc: 28.75%\n",
      "\t Val. Loss: 1.453 |  Val. Acc: 31.57%\n",
      "\t Relaxed Train. Acc: 79.22% | Relaxed Val. Acc: 71.67%\n",
      "Epoch: 18 | Time: 0.0m 35.71s\n",
      "\t Train Loss: 1.048 | Train Acc: 29.17%\n",
      "\t Val. Loss: 1.404 |  Val. Acc: 33.03%\n",
      "\t Relaxed Train. Acc: 79.44% | Relaxed Val. Acc: 73.04%\n",
      "Epoch: 19 | Time: 0.0m 35.72s\n",
      "\t Train Loss: 1.038 | Train Acc: 29.79%\n",
      "\t Val. Loss: 1.431 |  Val. Acc: 33.62%\n",
      "\t Relaxed Train. Acc: 79.77% | Relaxed Val. Acc: 72.80%\n",
      "Epoch: 20 | Time: 0.0m 35.70s\n",
      "\t Train Loss: 1.026 | Train Acc: 30.22%\n",
      "\t Val. Loss: 1.432 |  Val. Acc: 33.18%\n",
      "\t Relaxed Train. Acc: 80.12% | Relaxed Val. Acc: 72.80%\n",
      "Epoch: 21 | Time: 0.0m 35.70s\n",
      "\t Train Loss: 1.021 | Train Acc: 30.69%\n",
      "\t Val. Loss: 1.436 |  Val. Acc: 32.84%\n",
      "\t Relaxed Train. Acc: 80.34% | Relaxed Val. Acc: 72.91%\n",
      "Epoch: 22 | Time: 0.0m 35.71s\n",
      "\t Train Loss: 1.014 | Train Acc: 31.34%\n",
      "\t Val. Loss: 1.429 |  Val. Acc: 33.28%\n",
      "\t Relaxed Train. Acc: 80.62% | Relaxed Val. Acc: 72.84%\n",
      "Epoch: 23 | Time: 0.0m 35.69s\n",
      "\t Train Loss: 1.006 | Train Acc: 31.64%\n",
      "\t Val. Loss: 1.442 |  Val. Acc: 34.20%\n",
      "\t Relaxed Train. Acc: 80.84% | Relaxed Val. Acc: 72.72%\n",
      "Epoch: 24 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 1.003 | Train Acc: 31.75%\n",
      "\t Val. Loss: 1.423 |  Val. Acc: 34.52%\n",
      "\t Relaxed Train. Acc: 80.97% | Relaxed Val. Acc: 73.50%\n",
      "Epoch: 25 | Time: 0.0m 35.69s\n",
      "\t Train Loss: 1.001 | Train Acc: 32.29%\n",
      "\t Val. Loss: 1.413 |  Val. Acc: 33.52%\n",
      "\t Relaxed Train. Acc: 81.07% | Relaxed Val. Acc: 73.41%\n",
      "Epoch: 26 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 0.990 | Train Acc: 32.54%\n",
      "\t Val. Loss: 1.428 |  Val. Acc: 33.84%\n",
      "\t Relaxed Train. Acc: 81.38% | Relaxed Val. Acc: 73.11%\n",
      "Epoch: 27 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 0.985 | Train Acc: 32.81%\n",
      "\t Val. Loss: 1.455 |  Val. Acc: 35.01%\n",
      "\t Relaxed Train. Acc: 81.50% | Relaxed Val. Acc: 73.43%\n",
      "Epoch: 28 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 0.985 | Train Acc: 33.49%\n",
      "\t Val. Loss: 1.432 |  Val. Acc: 34.01%\n",
      "\t Relaxed Train. Acc: 81.54% | Relaxed Val. Acc: 73.24%\n",
      "Epoch: 29 | Time: 0.0m 35.68s\n",
      "\t Train Loss: 0.975 | Train Acc: 33.86%\n",
      "\t Val. Loss: 1.428 |  Val. Acc: 35.38%\n",
      "\t Relaxed Train. Acc: 81.88% | Relaxed Val. Acc: 74.18%\n",
      "Epoch: 30 | Time: 0.0m 35.66s\n",
      "\t Train Loss: 0.972 | Train Acc: 34.25%\n",
      "\t Val. Loss: 1.432 |  Val. Acc: 34.30%\n",
      "\t Relaxed Train. Acc: 82.04% | Relaxed Val. Acc: 73.47%\n",
      "Epoch: 31 | Time: 0.0m 35.67s\n",
      "\t Train Loss: 0.967 | Train Acc: 34.31%\n",
      "\t Val. Loss: 1.463 |  Val. Acc: 33.57%\n",
      "\t Relaxed Train. Acc: 82.16% | Relaxed Val. Acc: 72.65%\n",
      "Epoch: 32 | Time: 0.0m 35.66s\n",
      "\t Train Loss: 0.959 | Train Acc: 34.84%\n",
      "\t Val. Loss: 1.443 |  Val. Acc: 34.23%\n",
      "\t Relaxed Train. Acc: 82.42% | Relaxed Val. Acc: 73.37%\n",
      "Epoch: 33 | Time: 0.0m 35.67s\n",
      "\t Train Loss: 0.960 | Train Acc: 34.78%\n",
      "\t Val. Loss: 1.454 |  Val. Acc: 33.91%\n",
      "\t Relaxed Train. Acc: 82.37% | Relaxed Val. Acc: 73.15%\n",
      "Epoch: 34 | Time: 0.0m 35.66s\n",
      "\t Train Loss: 0.956 | Train Acc: 35.31%\n",
      "\t Val. Loss: 1.430 |  Val. Acc: 35.13%\n",
      "\t Relaxed Train. Acc: 82.53% | Relaxed Val. Acc: 73.76%\n",
      "Epoch: 35 | Time: 0.0m 35.65s\n",
      "\t Train Loss: 0.949 | Train Acc: 35.81%\n",
      "\t Val. Loss: 1.448 |  Val. Acc: 33.86%\n",
      "\t Relaxed Train. Acc: 82.83% | Relaxed Val. Acc: 73.37%\n",
      "Epoch: 36 | Time: 0.0m 35.66s\n",
      "\t Train Loss: 0.946 | Train Acc: 35.97%\n",
      "\t Val. Loss: 1.443 |  Val. Acc: 35.21%\n",
      "\t Relaxed Train. Acc: 82.90% | Relaxed Val. Acc: 74.31%\n",
      "Epoch: 37 | Time: 0.0m 35.65s\n",
      "\t Train Loss: 0.942 | Train Acc: 36.40%\n",
      "\t Val. Loss: 1.434 |  Val. Acc: 35.01%\n",
      "\t Relaxed Train. Acc: 83.05% | Relaxed Val. Acc: 73.74%\n",
      "Epoch: 38 | Time: 0.0m 35.65s\n",
      "\t Train Loss: 0.939 | Train Acc: 36.39%\n",
      "\t Val. Loss: 1.428 |  Val. Acc: 34.11%\n",
      "\t Relaxed Train. Acc: 83.03% | Relaxed Val. Acc: 73.83%\n",
      "Epoch: 39 | Time: 0.0m 35.65s\n",
      "\t Train Loss: 0.934 | Train Acc: 36.52%\n",
      "\t Val. Loss: 1.453 |  Val. Acc: 35.84%\n",
      "\t Relaxed Train. Acc: 83.23% | Relaxed Val. Acc: 74.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Time: 0.0m 35.64s\n",
      "\t Train Loss: 0.931 | Train Acc: 37.13%\n",
      "\t Val. Loss: 1.442 |  Val. Acc: 34.20%\n",
      "\t Relaxed Train. Acc: 83.37% | Relaxed Val. Acc: 73.91%\n",
      "Run: enc_embed size: 256 dec_embed size: 512, hid_size: 128, num_layers: 2, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>relxd valid acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>train acc</td><td>▁▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>train loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████▇█████████</td></tr><tr><td>valid loss</td><td>█▄▃▂▂▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>relxd train acc</td><td>0.83375</td></tr><tr><td>relxd valid acc</td><td>0.73906</td></tr><tr><td>train acc</td><td>0.37129</td></tr><tr><td>train loss</td><td>0.93054</td></tr><tr><td>valid acc</td><td>0.34204</td></tr><tr><td>valid loss</td><td>1.44243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-34</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/rqo2cy6g' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/rqo2cy6g</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_220753-rqo2cy6g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mj7ldib8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230525_223152-mj7ldib8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/mj7ldib8' target=\"_blank\">wise-sweep-35</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/mj7ldib8' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/mj7ldib8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,279,236 trainable parameters\n",
      "Epoch: 01 | Time: 1.0m 21.51s\n",
      "\t Train Loss: 1.817 | Train Acc: 7.31%\n",
      "\t Val. Loss: 1.574 |  Val. Acc: 23.41%\n",
      "\t Relaxed Train. Acc: 56.56% | Relaxed Val. Acc: 66.67%\n",
      "Epoch: 02 | Time: 1.0m 21.53s\n",
      "\t Train Loss: 1.242 | Train Acc: 18.90%\n",
      "\t Val. Loss: 1.464 |  Val. Acc: 30.86%\n",
      "\t Relaxed Train. Acc: 73.02% | Relaxed Val. Acc: 70.24%\n",
      "Epoch: 03 | Time: 1.0m 21.40s\n",
      "\t Train Loss: 1.121 | Train Acc: 24.73%\n",
      "\t Val. Loss: 1.410 |  Val. Acc: 34.33%\n",
      "\t Relaxed Train. Acc: 77.01% | Relaxed Val. Acc: 73.18%\n",
      "Epoch: 04 | Time: 1.0m 21.36s\n",
      "\t Train Loss: 1.057 | Train Acc: 28.64%\n",
      "\t Val. Loss: 1.398 |  Val. Acc: 35.03%\n",
      "\t Relaxed Train. Acc: 79.26% | Relaxed Val. Acc: 73.17%\n",
      "Epoch: 05 | Time: 1.0m 21.34s\n",
      "\t Train Loss: 1.015 | Train Acc: 30.82%\n",
      "\t Val. Loss: 1.390 |  Val. Acc: 36.35%\n",
      "\t Relaxed Train. Acc: 80.64% | Relaxed Val. Acc: 73.81%\n",
      "Epoch: 06 | Time: 1.0m 21.32s\n",
      "\t Train Loss: 0.983 | Train Acc: 33.23%\n",
      "\t Val. Loss: 1.361 |  Val. Acc: 38.01%\n",
      "\t Relaxed Train. Acc: 81.72% | Relaxed Val. Acc: 74.79%\n",
      "Epoch: 07 | Time: 1.0m 21.29s\n",
      "\t Train Loss: 0.951 | Train Acc: 35.10%\n",
      "\t Val. Loss: 1.372 |  Val. Acc: 38.53%\n",
      "\t Relaxed Train. Acc: 82.81% | Relaxed Val. Acc: 75.63%\n",
      "Epoch: 08 | Time: 1.0m 21.27s\n",
      "\t Train Loss: 0.935 | Train Acc: 36.75%\n",
      "\t Val. Loss: 1.392 |  Val. Acc: 39.65%\n",
      "\t Relaxed Train. Acc: 83.36% | Relaxed Val. Acc: 75.34%\n",
      "Epoch: 09 | Time: 1.0m 21.35s\n",
      "\t Train Loss: 0.915 | Train Acc: 38.06%\n",
      "\t Val. Loss: 1.391 |  Val. Acc: 39.43%\n",
      "\t Relaxed Train. Acc: 84.04% | Relaxed Val. Acc: 75.13%\n",
      "Epoch: 10 | Time: 1.0m 21.34s\n",
      "\t Train Loss: 0.898 | Train Acc: 39.61%\n",
      "\t Val. Loss: 1.393 |  Val. Acc: 40.06%\n",
      "\t Relaxed Train. Acc: 84.58% | Relaxed Val. Acc: 75.58%\n",
      "Epoch: 11 | Time: 1.0m 21.23s\n",
      "\t Train Loss: 0.886 | Train Acc: 40.60%\n",
      "\t Val. Loss: 1.394 |  Val. Acc: 39.55%\n",
      "\t Relaxed Train. Acc: 84.99% | Relaxed Val. Acc: 75.75%\n",
      "Epoch: 12 | Time: 1.0m 21.21s\n",
      "\t Train Loss: 0.875 | Train Acc: 41.52%\n",
      "\t Val. Loss: 1.385 |  Val. Acc: 40.14%\n",
      "\t Relaxed Train. Acc: 85.33% | Relaxed Val. Acc: 76.04%\n",
      "Epoch: 13 | Time: 1.0m 21.21s\n",
      "\t Train Loss: 0.863 | Train Acc: 42.60%\n",
      "\t Val. Loss: 1.383 |  Val. Acc: 40.70%\n",
      "\t Relaxed Train. Acc: 85.79% | Relaxed Val. Acc: 76.31%\n",
      "Epoch: 14 | Time: 1.0m 21.27s\n",
      "\t Train Loss: 0.849 | Train Acc: 43.34%\n",
      "\t Val. Loss: 1.390 |  Val. Acc: 41.09%\n",
      "\t Relaxed Train. Acc: 86.20% | Relaxed Val. Acc: 76.42%\n",
      "Epoch: 15 | Time: 1.0m 21.27s\n",
      "\t Train Loss: 0.846 | Train Acc: 44.08%\n",
      "\t Val. Loss: 1.370 |  Val. Acc: 41.63%\n",
      "\t Relaxed Train. Acc: 86.41% | Relaxed Val. Acc: 76.54%\n",
      "Epoch: 16 | Time: 1.0m 21.18s\n",
      "\t Train Loss: 0.836 | Train Acc: 44.66%\n",
      "\t Val. Loss: 1.404 |  Val. Acc: 40.19%\n",
      "\t Relaxed Train. Acc: 86.60% | Relaxed Val. Acc: 76.16%\n",
      "Epoch: 17 | Time: 1.0m 21.17s\n",
      "\t Train Loss: 0.829 | Train Acc: 45.16%\n",
      "\t Val. Loss: 1.411 |  Val. Acc: 41.09%\n",
      "\t Relaxed Train. Acc: 86.83% | Relaxed Val. Acc: 76.26%\n",
      "Epoch: 18 | Time: 1.0m 21.25s\n",
      "\t Train Loss: 0.821 | Train Acc: 46.10%\n",
      "\t Val. Loss: 1.382 |  Val. Acc: 42.02%\n",
      "\t Relaxed Train. Acc: 87.13% | Relaxed Val. Acc: 76.89%\n",
      "Epoch: 19 | Time: 1.0m 21.24s\n",
      "\t Train Loss: 0.815 | Train Acc: 46.67%\n",
      "\t Val. Loss: 1.414 |  Val. Acc: 41.33%\n",
      "\t Relaxed Train. Acc: 87.34% | Relaxed Val. Acc: 76.70%\n",
      "Epoch: 20 | Time: 1.0m 21.23s\n",
      "\t Train Loss: 0.811 | Train Acc: 47.16%\n",
      "\t Val. Loss: 1.420 |  Val. Acc: 41.77%\n",
      "\t Relaxed Train. Acc: 87.50% | Relaxed Val. Acc: 76.40%\n",
      "Epoch: 21 | Time: 1.0m 21.15s\n",
      "\t Train Loss: 0.804 | Train Acc: 47.69%\n",
      "\t Val. Loss: 1.412 |  Val. Acc: 41.31%\n",
      "\t Relaxed Train. Acc: 87.70% | Relaxed Val. Acc: 76.63%\n",
      "Epoch: 22 | Time: 1.0m 21.14s\n",
      "\t Train Loss: 0.795 | Train Acc: 48.43%\n",
      "\t Val. Loss: 1.429 |  Val. Acc: 41.92%\n",
      "\t Relaxed Train. Acc: 88.00% | Relaxed Val. Acc: 76.47%\n",
      "Epoch: 23 | Time: 1.0m 21.13s\n",
      "\t Train Loss: 0.792 | Train Acc: 48.65%\n",
      "\t Val. Loss: 1.413 |  Val. Acc: 41.21%\n",
      "\t Relaxed Train. Acc: 88.07% | Relaxed Val. Acc: 76.82%\n",
      "Epoch: 24 | Time: 1.0m 21.22s\n",
      "\t Train Loss: 0.788 | Train Acc: 49.27%\n",
      "\t Val. Loss: 1.430 |  Val. Acc: 42.02%\n",
      "\t Relaxed Train. Acc: 88.20% | Relaxed Val. Acc: 77.08%\n",
      "Epoch: 25 | Time: 1.0m 21.21s\n",
      "\t Train Loss: 0.785 | Train Acc: 49.74%\n",
      "\t Val. Loss: 1.424 |  Val. Acc: 41.48%\n",
      "\t Relaxed Train. Acc: 88.32% | Relaxed Val. Acc: 76.84%\n",
      "Epoch: 26 | Time: 1.0m 21.12s\n",
      "\t Train Loss: 0.782 | Train Acc: 49.60%\n",
      "\t Val. Loss: 1.418 |  Val. Acc: 41.50%\n",
      "\t Relaxed Train. Acc: 88.39% | Relaxed Val. Acc: 76.89%\n",
      "Epoch: 27 | Time: 1.0m 21.19s\n",
      "\t Train Loss: 0.777 | Train Acc: 50.26%\n",
      "\t Val. Loss: 1.450 |  Val. Acc: 42.02%\n",
      "\t Relaxed Train. Acc: 88.59% | Relaxed Val. Acc: 76.81%\n",
      "Epoch: 28 | Time: 1.0m 21.11s\n",
      "\t Train Loss: 0.773 | Train Acc: 50.70%\n",
      "\t Val. Loss: 1.449 |  Val. Acc: 41.06%\n",
      "\t Relaxed Train. Acc: 88.74% | Relaxed Val. Acc: 76.51%\n",
      "Epoch: 29 | Time: 1.0m 21.19s\n",
      "\t Train Loss: 0.768 | Train Acc: 51.19%\n",
      "\t Val. Loss: 1.471 |  Val. Acc: 41.31%\n",
      "\t Relaxed Train. Acc: 88.91% | Relaxed Val. Acc: 76.38%\n",
      "Epoch: 30 | Time: 1.0m 21.09s\n",
      "\t Train Loss: 0.766 | Train Acc: 51.70%\n",
      "\t Val. Loss: 1.448 |  Val. Acc: 41.33%\n",
      "\t Relaxed Train. Acc: 89.01% | Relaxed Val. Acc: 76.69%\n",
      "Epoch: 31 | Time: 1.0m 21.18s\n",
      "\t Train Loss: 0.765 | Train Acc: 51.75%\n",
      "\t Val. Loss: 1.454 |  Val. Acc: 41.19%\n",
      "\t Relaxed Train. Acc: 88.98% | Relaxed Val. Acc: 76.58%\n",
      "Epoch: 32 | Time: 1.0m 21.11s\n",
      "\t Train Loss: 0.762 | Train Acc: 51.69%\n",
      "\t Val. Loss: 1.448 |  Val. Acc: 41.72%\n",
      "\t Relaxed Train. Acc: 89.09% | Relaxed Val. Acc: 76.70%\n",
      "Epoch: 33 | Time: 1.0m 21.18s\n",
      "\t Train Loss: 0.755 | Train Acc: 52.68%\n",
      "\t Val. Loss: 1.482 |  Val. Acc: 41.11%\n",
      "\t Relaxed Train. Acc: 89.35% | Relaxed Val. Acc: 76.33%\n",
      "Epoch: 34 | Time: 1.0m 21.08s\n",
      "\t Train Loss: 0.752 | Train Acc: 52.95%\n",
      "\t Val. Loss: 1.468 |  Val. Acc: 41.82%\n",
      "\t Relaxed Train. Acc: 89.41% | Relaxed Val. Acc: 76.70%\n",
      "Epoch: 35 | Time: 1.0m 21.09s\n",
      "\t Train Loss: 0.749 | Train Acc: 53.04%\n",
      "\t Val. Loss: 1.514 |  Val. Acc: 41.60%\n",
      "\t Relaxed Train. Acc: 89.51% | Relaxed Val. Acc: 76.13%\n",
      "Epoch: 36 | Time: 1.0m 21.07s\n",
      "\t Train Loss: 0.751 | Train Acc: 53.45%\n",
      "\t Val. Loss: 1.495 |  Val. Acc: 41.85%\n",
      "\t Relaxed Train. Acc: 89.48% | Relaxed Val. Acc: 76.46%\n",
      "Epoch: 37 | Time: 1.0m 21.08s\n",
      "\t Train Loss: 0.746 | Train Acc: 53.63%\n",
      "\t Val. Loss: 1.477 |  Val. Acc: 42.24%\n",
      "\t Relaxed Train. Acc: 89.60% | Relaxed Val. Acc: 77.15%\n",
      "Epoch: 38 | Time: 1.0m 21.08s\n",
      "\t Train Loss: 0.744 | Train Acc: 53.92%\n",
      "\t Val. Loss: 1.494 |  Val. Acc: 41.02%\n",
      "\t Relaxed Train. Acc: 89.67% | Relaxed Val. Acc: 76.25%\n",
      "Epoch: 39 | Time: 1.0m 21.17s\n",
      "\t Train Loss: 0.741 | Train Acc: 53.87%\n",
      "\t Val. Loss: 1.498 |  Val. Acc: 41.41%\n",
      "\t Relaxed Train. Acc: 89.79% | Relaxed Val. Acc: 76.15%\n",
      "Epoch: 40 | Time: 1.0m 21.07s\n",
      "\t Train Loss: 0.738 | Train Acc: 54.61%\n",
      "\t Val. Loss: 1.488 |  Val. Acc: 40.87%\n",
      "\t Relaxed Train. Acc: 89.90% | Relaxed Val. Acc: 76.38%\n",
      "Run: enc_embed size: 128 dec_embed size: 256, hid_size: 128, num_layers: 3, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>relxd valid acc</td><td>▁▃▅▅▆▆▇▇▇▇▇▇▇██▇▇██▇████████▇███▇█▇██▇▇▇</td></tr><tr><td>train acc</td><td>▁▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train loss</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇██▇███████████████████████▇</td></tr><tr><td>valid loss</td><td>█▄▃▂▂▁▁▂▂▂▂▂▂▂▁▂▃▂▃▃▃▃▃▃▃▃▄▄▅▄▄▄▅▅▆▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>relxd train acc</td><td>0.89898</td></tr><tr><td>relxd valid acc</td><td>0.76381</td></tr><tr><td>train acc</td><td>0.54607</td></tr><tr><td>train loss</td><td>0.73829</td></tr><tr><td>valid acc</td><td>0.40869</td></tr><tr><td>valid loss</td><td>1.48754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wise-sweep-35</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/mj7ldib8' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/mj7ldib8</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_223152-mj7ldib8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b11o7b6v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230525_232621-b11o7b6v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/b11o7b6v' target=\"_blank\">earthy-sweep-36</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/b11o7b6v' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/b11o7b6v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,073,732 trainable parameters\n",
      "Epoch: 01 | Time: 2.0m 37.85s\n",
      "\t Train Loss: 1.471 | Train Acc: 14.62%\n",
      "\t Val. Loss: 1.424 |  Val. Acc: 31.84%\n",
      "\t Relaxed Train. Acc: 66.31% | Relaxed Val. Acc: 71.78%\n",
      "Epoch: 02 | Time: 2.0m 38.07s\n",
      "\t Train Loss: 1.055 | Train Acc: 28.43%\n",
      "\t Val. Loss: 1.359 |  Val. Acc: 36.11%\n",
      "\t Relaxed Train. Acc: 79.24% | Relaxed Val. Acc: 73.85%\n",
      "Epoch: 03 | Time: 2.0m 38.00s\n",
      "\t Train Loss: 0.958 | Train Acc: 34.64%\n",
      "\t Val. Loss: 1.351 |  Val. Acc: 37.23%\n",
      "\t Relaxed Train. Acc: 82.49% | Relaxed Val. Acc: 74.81%\n",
      "Epoch: 04 | Time: 2.0m 37.99s\n",
      "\t Train Loss: 0.903 | Train Acc: 39.00%\n",
      "\t Val. Loss: 1.358 |  Val. Acc: 39.92%\n",
      "\t Relaxed Train. Acc: 84.38% | Relaxed Val. Acc: 76.07%\n",
      "Epoch: 05 | Time: 2.0m 37.93s\n",
      "\t Train Loss: 0.859 | Train Acc: 42.59%\n",
      "\t Val. Loss: 1.358 |  Val. Acc: 38.31%\n",
      "\t Relaxed Train. Acc: 85.81% | Relaxed Val. Acc: 75.83%\n",
      "Epoch: 06 | Time: 2.0m 37.87s\n",
      "\t Train Loss: 0.826 | Train Acc: 45.79%\n",
      "\t Val. Loss: 1.370 |  Val. Acc: 40.58%\n",
      "\t Relaxed Train. Acc: 86.94% | Relaxed Val. Acc: 76.45%\n",
      "Epoch: 07 | Time: 2.0m 37.87s\n",
      "\t Train Loss: 0.801 | Train Acc: 47.54%\n",
      "\t Val. Loss: 1.411 |  Val. Acc: 40.38%\n",
      "\t Relaxed Train. Acc: 87.74% | Relaxed Val. Acc: 76.45%\n",
      "Epoch: 08 | Time: 2.0m 37.80s\n",
      "\t Train Loss: 0.781 | Train Acc: 49.84%\n",
      "\t Val. Loss: 1.401 |  Val. Acc: 41.82%\n",
      "\t Relaxed Train. Acc: 88.42% | Relaxed Val. Acc: 77.31%\n",
      "Epoch: 09 | Time: 2.0m 37.86s\n",
      "\t Train Loss: 0.764 | Train Acc: 51.56%\n",
      "\t Val. Loss: 1.421 |  Val. Acc: 40.77%\n",
      "\t Relaxed Train. Acc: 88.93% | Relaxed Val. Acc: 76.48%\n",
      "Epoch: 10 | Time: 2.0m 37.81s\n",
      "\t Train Loss: 0.750 | Train Acc: 53.31%\n",
      "\t Val. Loss: 1.415 |  Val. Acc: 40.04%\n",
      "\t Relaxed Train. Acc: 89.47% | Relaxed Val. Acc: 76.73%\n",
      "Epoch: 11 | Time: 2.0m 37.79s\n",
      "\t Train Loss: 0.740 | Train Acc: 54.43%\n",
      "\t Val. Loss: 1.422 |  Val. Acc: 40.75%\n",
      "\t Relaxed Train. Acc: 89.76% | Relaxed Val. Acc: 77.21%\n",
      "Epoch: 12 | Time: 2.0m 37.74s\n",
      "\t Train Loss: 0.732 | Train Acc: 55.04%\n",
      "\t Val. Loss: 1.468 |  Val. Acc: 40.75%\n",
      "\t Relaxed Train. Acc: 89.99% | Relaxed Val. Acc: 76.59%\n",
      "Epoch: 13 | Time: 2.0m 37.80s\n",
      "\t Train Loss: 0.724 | Train Acc: 55.98%\n",
      "\t Val. Loss: 1.478 |  Val. Acc: 41.60%\n",
      "\t Relaxed Train. Acc: 90.30% | Relaxed Val. Acc: 76.73%\n",
      "Epoch: 14 | Time: 2.0m 37.74s\n",
      "\t Train Loss: 0.716 | Train Acc: 56.80%\n",
      "\t Val. Loss: 1.499 |  Val. Acc: 41.36%\n",
      "\t Relaxed Train. Acc: 90.54% | Relaxed Val. Acc: 76.91%\n",
      "Epoch: 15 | Time: 2.0m 37.79s\n",
      "\t Train Loss: 0.719 | Train Acc: 57.29%\n",
      "\t Val. Loss: 1.498 |  Val. Acc: 40.33%\n",
      "\t Relaxed Train. Acc: 90.54% | Relaxed Val. Acc: 76.39%\n",
      "Epoch: 16 | Time: 2.0m 37.78s\n",
      "\t Train Loss: 0.712 | Train Acc: 57.63%\n",
      "\t Val. Loss: 1.510 |  Val. Acc: 39.58%\n",
      "\t Relaxed Train. Acc: 90.70% | Relaxed Val. Acc: 76.46%\n",
      "Epoch: 17 | Time: 2.0m 37.79s\n",
      "\t Train Loss: 0.712 | Train Acc: 57.58%\n",
      "\t Val. Loss: 1.484 |  Val. Acc: 40.92%\n",
      "\t Relaxed Train. Acc: 90.70% | Relaxed Val. Acc: 76.82%\n",
      "Epoch: 18 | Time: 2.0m 37.73s\n",
      "\t Train Loss: 0.705 | Train Acc: 58.31%\n",
      "\t Val. Loss: 1.484 |  Val. Acc: 40.04%\n",
      "\t Relaxed Train. Acc: 90.90% | Relaxed Val. Acc: 76.88%\n",
      "Epoch: 19 | Time: 2.0m 37.76s\n",
      "\t Train Loss: 0.703 | Train Acc: 58.44%\n",
      "\t Val. Loss: 1.504 |  Val. Acc: 41.46%\n",
      "\t Relaxed Train. Acc: 91.02% | Relaxed Val. Acc: 76.88%\n",
      "Epoch: 20 | Time: 2.0m 37.78s\n",
      "\t Train Loss: 0.706 | Train Acc: 58.23%\n",
      "\t Val. Loss: 1.517 |  Val. Acc: 41.16%\n",
      "\t Relaxed Train. Acc: 90.87% | Relaxed Val. Acc: 76.86%\n",
      "Run: enc_embed size: 128 dec_embed size: 16, hid_size: 512, num_layers: 3, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>relxd train acc</td><td>▁▅▆▆▇▇▇▇▇███████████</td></tr><tr><td>relxd valid acc</td><td>▁▄▅▆▆▇▇█▇▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇████████</td></tr><tr><td>train loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▄▅▇▆▇▇█▇▇▇▇██▇▆▇▇██</td></tr><tr><td>valid loss</td><td>▄▁▁▁▁▂▄▃▄▄▄▆▆▇▇█▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>relxd train acc</td><td>0.90869</td></tr><tr><td>relxd valid acc</td><td>0.76863</td></tr><tr><td>train acc</td><td>0.58227</td></tr><tr><td>train loss</td><td>0.70588</td></tr><tr><td>valid acc</td><td>0.41162</td></tr><tr><td>valid loss</td><td>1.51732</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-36</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/b11o7b6v' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/b11o7b6v</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_232621-b11o7b6v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dfx1r7ay with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_001914-dfx1r7ay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/dfx1r7ay' target=\"_blank\">hearty-sweep-37</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/dfx1r7ay' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/dfx1r7ay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,079,236 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 31.26s\n",
      "\t Train Loss: 1.651 | Train Acc: 9.53%\n",
      "\t Val. Loss: 1.550 |  Val. Acc: 24.15%\n",
      "\t Relaxed Train. Acc: 60.42% | Relaxed Val. Acc: 67.17%\n",
      "Epoch: 02 | Time: 0.0m 31.14s\n",
      "\t Train Loss: 1.218 | Train Acc: 21.10%\n",
      "\t Val. Loss: 1.533 |  Val. Acc: 27.03%\n",
      "\t Relaxed Train. Acc: 73.80% | Relaxed Val. Acc: 69.07%\n",
      "Epoch: 03 | Time: 0.0m 31.07s\n",
      "\t Train Loss: 1.104 | Train Acc: 26.58%\n",
      "\t Val. Loss: 1.491 |  Val. Acc: 29.96%\n",
      "\t Relaxed Train. Acc: 77.67% | Relaxed Val. Acc: 69.97%\n",
      "Epoch: 04 | Time: 0.0m 31.03s\n",
      "\t Train Loss: 1.046 | Train Acc: 30.38%\n",
      "\t Val. Loss: 1.476 |  Val. Acc: 31.74%\n",
      "\t Relaxed Train. Acc: 79.72% | Relaxed Val. Acc: 71.54%\n",
      "Epoch: 05 | Time: 0.0m 30.99s\n",
      "\t Train Loss: 1.001 | Train Acc: 33.07%\n",
      "\t Val. Loss: 1.454 |  Val. Acc: 32.84%\n",
      "\t Relaxed Train. Acc: 81.19% | Relaxed Val. Acc: 72.95%\n",
      "Epoch: 06 | Time: 0.0m 30.97s\n",
      "\t Train Loss: 0.960 | Train Acc: 36.20%\n",
      "\t Val. Loss: 1.493 |  Val. Acc: 33.64%\n",
      "\t Relaxed Train. Acc: 82.61% | Relaxed Val. Acc: 72.62%\n",
      "Epoch: 07 | Time: 0.0m 30.94s\n",
      "\t Train Loss: 0.927 | Train Acc: 38.78%\n",
      "\t Val. Loss: 1.488 |  Val. Acc: 33.74%\n",
      "\t Relaxed Train. Acc: 83.82% | Relaxed Val. Acc: 72.61%\n",
      "Epoch: 08 | Time: 0.0m 30.92s\n",
      "\t Train Loss: 0.900 | Train Acc: 40.88%\n",
      "\t Val. Loss: 1.544 |  Val. Acc: 33.91%\n",
      "\t Relaxed Train. Acc: 84.69% | Relaxed Val. Acc: 72.48%\n",
      "Epoch: 09 | Time: 0.0m 30.89s\n",
      "\t Train Loss: 0.880 | Train Acc: 42.88%\n",
      "\t Val. Loss: 1.527 |  Val. Acc: 34.47%\n",
      "\t Relaxed Train. Acc: 85.39% | Relaxed Val. Acc: 73.02%\n",
      "Epoch: 10 | Time: 0.0m 30.91s\n",
      "\t Train Loss: 0.861 | Train Acc: 44.92%\n",
      "\t Val. Loss: 1.535 |  Val. Acc: 33.81%\n",
      "\t Relaxed Train. Acc: 86.08% | Relaxed Val. Acc: 73.05%\n",
      "Epoch: 11 | Time: 0.0m 30.86s\n",
      "\t Train Loss: 0.844 | Train Acc: 46.39%\n",
      "\t Val. Loss: 1.580 |  Val. Acc: 33.08%\n",
      "\t Relaxed Train. Acc: 86.63% | Relaxed Val. Acc: 72.16%\n",
      "Epoch: 12 | Time: 0.0m 30.84s\n",
      "\t Train Loss: 0.826 | Train Acc: 47.75%\n",
      "\t Val. Loss: 1.578 |  Val. Acc: 34.74%\n",
      "\t Relaxed Train. Acc: 87.24% | Relaxed Val. Acc: 72.93%\n",
      "Epoch: 13 | Time: 0.0m 30.83s\n",
      "\t Train Loss: 0.812 | Train Acc: 49.62%\n",
      "\t Val. Loss: 1.580 |  Val. Acc: 33.25%\n",
      "\t Relaxed Train. Acc: 87.74% | Relaxed Val. Acc: 72.89%\n",
      "Epoch: 14 | Time: 0.0m 30.85s\n",
      "\t Train Loss: 0.801 | Train Acc: 50.49%\n",
      "\t Val. Loss: 1.606 |  Val. Acc: 34.28%\n",
      "\t Relaxed Train. Acc: 88.11% | Relaxed Val. Acc: 73.03%\n",
      "Epoch: 15 | Time: 0.0m 30.80s\n",
      "\t Train Loss: 0.794 | Train Acc: 51.48%\n",
      "\t Val. Loss: 1.600 |  Val. Acc: 33.64%\n",
      "\t Relaxed Train. Acc: 88.38% | Relaxed Val. Acc: 73.08%\n",
      "Epoch: 16 | Time: 0.0m 30.80s\n",
      "\t Train Loss: 0.787 | Train Acc: 52.21%\n",
      "\t Val. Loss: 1.637 |  Val. Acc: 33.06%\n",
      "\t Relaxed Train. Acc: 88.54% | Relaxed Val. Acc: 72.22%\n",
      "Epoch: 17 | Time: 0.0m 30.79s\n",
      "\t Train Loss: 0.781 | Train Acc: 52.44%\n",
      "\t Val. Loss: 1.657 |  Val. Acc: 32.25%\n",
      "\t Relaxed Train. Acc: 88.75% | Relaxed Val. Acc: 72.56%\n",
      "Epoch: 18 | Time: 0.0m 30.79s\n",
      "\t Train Loss: 0.776 | Train Acc: 53.35%\n",
      "\t Val. Loss: 1.665 |  Val. Acc: 31.47%\n",
      "\t Relaxed Train. Acc: 88.89% | Relaxed Val. Acc: 71.70%\n",
      "Epoch: 19 | Time: 0.0m 30.76s\n",
      "\t Train Loss: 0.766 | Train Acc: 54.21%\n",
      "\t Val. Loss: 1.652 |  Val. Acc: 32.20%\n",
      "\t Relaxed Train. Acc: 89.22% | Relaxed Val. Acc: 72.39%\n",
      "Epoch: 20 | Time: 0.0m 30.76s\n",
      "\t Train Loss: 0.764 | Train Acc: 54.57%\n",
      "\t Val. Loss: 1.670 |  Val. Acc: 32.20%\n",
      "\t Relaxed Train. Acc: 89.34% | Relaxed Val. Acc: 72.36%\n",
      "Epoch: 21 | Time: 0.0m 30.77s\n",
      "\t Train Loss: 0.755 | Train Acc: 55.49%\n",
      "\t Val. Loss: 1.682 |  Val. Acc: 31.88%\n",
      "\t Relaxed Train. Acc: 89.64% | Relaxed Val. Acc: 72.33%\n",
      "Epoch: 22 | Time: 0.0m 30.75s\n",
      "\t Train Loss: 0.755 | Train Acc: 55.48%\n",
      "\t Val. Loss: 1.707 |  Val. Acc: 32.62%\n",
      "\t Relaxed Train. Acc: 89.62% | Relaxed Val. Acc: 72.00%\n",
      "Epoch: 23 | Time: 0.0m 30.77s\n",
      "\t Train Loss: 0.750 | Train Acc: 55.83%\n",
      "\t Val. Loss: 1.706 |  Val. Acc: 31.20%\n",
      "\t Relaxed Train. Acc: 89.74% | Relaxed Val. Acc: 71.64%\n",
      "Epoch: 24 | Time: 0.0m 30.76s\n",
      "\t Train Loss: 0.752 | Train Acc: 55.72%\n",
      "\t Val. Loss: 1.720 |  Val. Acc: 31.45%\n",
      "\t Relaxed Train. Acc: 89.65% | Relaxed Val. Acc: 72.01%\n",
      "Epoch: 25 | Time: 0.0m 30.75s\n",
      "\t Train Loss: 0.744 | Train Acc: 56.88%\n",
      "\t Val. Loss: 1.723 |  Val. Acc: 31.81%\n",
      "\t Relaxed Train. Acc: 90.00% | Relaxed Val. Acc: 72.17%\n",
      "Epoch: 26 | Time: 0.0m 30.73s\n",
      "\t Train Loss: 0.741 | Train Acc: 57.29%\n",
      "\t Val. Loss: 1.714 |  Val. Acc: 32.52%\n",
      "\t Relaxed Train. Acc: 90.08% | Relaxed Val. Acc: 72.38%\n",
      "Epoch: 27 | Time: 0.0m 30.77s\n",
      "\t Train Loss: 0.744 | Train Acc: 56.89%\n",
      "\t Val. Loss: 1.709 |  Val. Acc: 32.10%\n",
      "\t Relaxed Train. Acc: 89.99% | Relaxed Val. Acc: 71.95%\n",
      "Epoch: 28 | Time: 0.0m 30.75s\n",
      "\t Train Loss: 0.745 | Train Acc: 56.93%\n",
      "\t Val. Loss: 1.719 |  Val. Acc: 31.49%\n",
      "\t Relaxed Train. Acc: 89.95% | Relaxed Val. Acc: 71.98%\n",
      "Epoch: 29 | Time: 0.0m 30.74s\n",
      "\t Train Loss: 0.740 | Train Acc: 57.31%\n",
      "\t Val. Loss: 1.730 |  Val. Acc: 31.45%\n",
      "\t Relaxed Train. Acc: 90.12% | Relaxed Val. Acc: 72.28%\n",
      "Epoch: 30 | Time: 0.0m 30.73s\n",
      "\t Train Loss: 0.738 | Train Acc: 57.52%\n",
      "\t Val. Loss: 1.748 |  Val. Acc: 31.23%\n",
      "\t Relaxed Train. Acc: 90.18% | Relaxed Val. Acc: 71.76%\n",
      "Epoch: 31 | Time: 0.0m 30.72s\n",
      "\t Train Loss: 0.737 | Train Acc: 58.01%\n",
      "\t Val. Loss: 1.734 |  Val. Acc: 31.64%\n",
      "\t Relaxed Train. Acc: 90.26% | Relaxed Val. Acc: 71.79%\n",
      "Epoch: 32 | Time: 0.0m 30.73s\n",
      "\t Train Loss: 0.733 | Train Acc: 57.74%\n",
      "\t Val. Loss: 1.770 |  Val. Acc: 31.40%\n",
      "\t Relaxed Train. Acc: 90.36% | Relaxed Val. Acc: 71.61%\n",
      "Epoch: 33 | Time: 0.0m 30.72s\n",
      "\t Train Loss: 0.734 | Train Acc: 57.73%\n",
      "\t Val. Loss: 1.781 |  Val. Acc: 31.62%\n",
      "\t Relaxed Train. Acc: 90.32% | Relaxed Val. Acc: 71.62%\n",
      "Epoch: 34 | Time: 0.0m 30.74s\n",
      "\t Train Loss: 0.730 | Train Acc: 58.42%\n",
      "\t Val. Loss: 1.770 |  Val. Acc: 30.81%\n",
      "\t Relaxed Train. Acc: 90.47% | Relaxed Val. Acc: 71.50%\n",
      "Epoch: 35 | Time: 0.0m 30.71s\n",
      "\t Train Loss: 0.730 | Train Acc: 58.49%\n",
      "\t Val. Loss: 1.768 |  Val. Acc: 30.00%\n",
      "\t Relaxed Train. Acc: 90.46% | Relaxed Val. Acc: 71.47%\n",
      "Epoch: 36 | Time: 0.0m 30.72s\n",
      "\t Train Loss: 0.732 | Train Acc: 58.30%\n",
      "\t Val. Loss: 1.760 |  Val. Acc: 31.59%\n",
      "\t Relaxed Train. Acc: 90.47% | Relaxed Val. Acc: 71.64%\n",
      "Epoch: 37 | Time: 0.0m 30.74s\n",
      "\t Train Loss: 0.736 | Train Acc: 57.96%\n",
      "\t Val. Loss: 1.801 |  Val. Acc: 31.84%\n",
      "\t Relaxed Train. Acc: 90.27% | Relaxed Val. Acc: 71.33%\n",
      "Epoch: 38 | Time: 0.0m 30.71s\n",
      "\t Train Loss: 0.735 | Train Acc: 58.10%\n",
      "\t Val. Loss: 1.778 |  Val. Acc: 31.86%\n",
      "\t Relaxed Train. Acc: 90.30% | Relaxed Val. Acc: 71.59%\n",
      "Epoch: 39 | Time: 0.0m 30.71s\n",
      "\t Train Loss: 0.727 | Train Acc: 58.65%\n",
      "\t Val. Loss: 1.763 |  Val. Acc: 33.23%\n",
      "\t Relaxed Train. Acc: 90.50% | Relaxed Val. Acc: 72.51%\n",
      "Epoch: 40 | Time: 0.0m 30.75s\n",
      "\t Train Loss: 0.732 | Train Acc: 58.30%\n",
      "\t Val. Loss: 1.769 |  Val. Acc: 31.93%\n",
      "\t Relaxed Train. Acc: 90.41% | Relaxed Val. Acc: 71.54%\n",
      "Run: enc_embed size: 128 dec_embed size: 32, hid_size: 256, num_layers: 1, cell_modegru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>relxd valid acc</td><td>▁▃▄▆█▇▇▇██▇████▇▇▆▇▇▇▇▆▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▇▆</td></tr><tr><td>train acc</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>train loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▃▅▆▇▇▇▇█▇▇█▇█▇▇▆▆▆▆▆▇▆▆▆▇▆▆▆▆▆▆▆▅▅▆▆▆▇▆</td></tr><tr><td>valid loss</td><td>▃▃▂▁▁▂▂▃▂▃▄▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>relxd train acc</td><td>0.90405</td></tr><tr><td>relxd valid acc</td><td>0.7154</td></tr><tr><td>train acc</td><td>0.58305</td></tr><tr><td>train loss</td><td>0.73221</td></tr><tr><td>valid acc</td><td>0.31934</td></tr><tr><td>valid loss</td><td>1.76905</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-37</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/dfx1r7ay' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/dfx1r7ay</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_001914-dfx1r7ay/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r21kns0f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_004001-r21kns0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/r21kns0f' target=\"_blank\">firm-sweep-38</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/r21kns0f' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/r21kns0f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 60,868 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 26.85s\n",
      "\t Train Loss: 2.398 | Train Acc: 0.66%\n",
      "\t Val. Loss: 2.161 |  Val. Acc: 5.42%\n",
      "\t Relaxed Train. Acc: 40.55% | Relaxed Val. Acc: 48.47%\n",
      "Epoch: 02 | Time: 0.0m 26.83s\n",
      "\t Train Loss: 1.892 | Train Acc: 3.21%\n",
      "\t Val. Loss: 1.953 |  Val. Acc: 8.37%\n",
      "\t Relaxed Train. Acc: 53.11% | Relaxed Val. Acc: 54.12%\n",
      "Epoch: 03 | Time: 0.0m 26.85s\n",
      "\t Train Loss: 1.724 | Train Acc: 5.49%\n",
      "\t Val. Loss: 1.844 |  Val. Acc: 11.43%\n",
      "\t Relaxed Train. Acc: 58.02% | Relaxed Val. Acc: 56.64%\n",
      "Epoch: 04 | Time: 0.0m 26.80s\n",
      "\t Train Loss: 1.632 | Train Acc: 7.51%\n",
      "\t Val. Loss: 1.804 |  Val. Acc: 13.38%\n",
      "\t Relaxed Train. Acc: 60.77% | Relaxed Val. Acc: 58.77%\n",
      "Epoch: 05 | Time: 0.0m 26.77s\n",
      "\t Train Loss: 1.576 | Train Acc: 8.98%\n",
      "\t Val. Loss: 1.762 |  Val. Acc: 15.75%\n",
      "\t Relaxed Train. Acc: 62.52% | Relaxed Val. Acc: 60.36%\n",
      "Epoch: 06 | Time: 0.0m 26.73s\n",
      "\t Train Loss: 1.532 | Train Acc: 10.19%\n",
      "\t Val. Loss: 1.732 |  Val. Acc: 16.50%\n",
      "\t Relaxed Train. Acc: 63.95% | Relaxed Val. Acc: 61.19%\n",
      "Epoch: 07 | Time: 0.0m 26.72s\n",
      "\t Train Loss: 1.496 | Train Acc: 11.15%\n",
      "\t Val. Loss: 1.714 |  Val. Acc: 16.85%\n",
      "\t Relaxed Train. Acc: 65.08% | Relaxed Val. Acc: 61.76%\n",
      "Epoch: 08 | Time: 0.0m 26.74s\n",
      "\t Train Loss: 1.474 | Train Acc: 11.77%\n",
      "\t Val. Loss: 1.721 |  Val. Acc: 18.55%\n",
      "\t Relaxed Train. Acc: 65.81% | Relaxed Val. Acc: 62.13%\n",
      "Epoch: 09 | Time: 0.0m 26.71s\n",
      "\t Train Loss: 1.456 | Train Acc: 12.40%\n",
      "\t Val. Loss: 1.686 |  Val. Acc: 19.43%\n",
      "\t Relaxed Train. Acc: 66.37% | Relaxed Val. Acc: 62.33%\n",
      "Epoch: 10 | Time: 0.0m 26.68s\n",
      "\t Train Loss: 1.433 | Train Acc: 13.09%\n",
      "\t Val. Loss: 1.675 |  Val. Acc: 19.29%\n",
      "\t Relaxed Train. Acc: 67.21% | Relaxed Val. Acc: 62.84%\n",
      "Epoch: 11 | Time: 0.0m 26.68s\n",
      "\t Train Loss: 1.426 | Train Acc: 13.39%\n",
      "\t Val. Loss: 1.664 |  Val. Acc: 20.12%\n",
      "\t Relaxed Train. Acc: 67.47% | Relaxed Val. Acc: 63.15%\n",
      "Epoch: 12 | Time: 0.0m 26.69s\n",
      "\t Train Loss: 1.406 | Train Acc: 14.05%\n",
      "\t Val. Loss: 1.665 |  Val. Acc: 20.95%\n",
      "\t Relaxed Train. Acc: 68.16% | Relaxed Val. Acc: 63.64%\n",
      "Epoch: 13 | Time: 0.0m 26.72s\n",
      "\t Train Loss: 1.394 | Train Acc: 14.52%\n",
      "\t Val. Loss: 1.667 |  Val. Acc: 20.53%\n",
      "\t Relaxed Train. Acc: 68.60% | Relaxed Val. Acc: 63.62%\n",
      "Epoch: 14 | Time: 0.0m 26.68s\n",
      "\t Train Loss: 1.376 | Train Acc: 14.99%\n",
      "\t Val. Loss: 1.664 |  Val. Acc: 20.70%\n",
      "\t Relaxed Train. Acc: 69.08% | Relaxed Val. Acc: 64.00%\n",
      "Epoch: 15 | Time: 0.0m 26.66s\n",
      "\t Train Loss: 1.375 | Train Acc: 15.29%\n",
      "\t Val. Loss: 1.641 |  Val. Acc: 21.19%\n",
      "\t Relaxed Train. Acc: 69.14% | Relaxed Val. Acc: 64.59%\n",
      "Epoch: 16 | Time: 0.0m 26.67s\n",
      "\t Train Loss: 1.362 | Train Acc: 15.78%\n",
      "\t Val. Loss: 1.640 |  Val. Acc: 21.92%\n",
      "\t Relaxed Train. Acc: 69.58% | Relaxed Val. Acc: 64.50%\n",
      "Epoch: 17 | Time: 0.0m 26.67s\n",
      "\t Train Loss: 1.353 | Train Acc: 15.81%\n",
      "\t Val. Loss: 1.647 |  Val. Acc: 21.39%\n",
      "\t Relaxed Train. Acc: 69.81% | Relaxed Val. Acc: 64.17%\n",
      "Epoch: 18 | Time: 0.0m 26.67s\n",
      "\t Train Loss: 1.348 | Train Acc: 16.17%\n",
      "\t Val. Loss: 1.637 |  Val. Acc: 22.73%\n",
      "\t Relaxed Train. Acc: 69.97% | Relaxed Val. Acc: 64.80%\n",
      "Epoch: 19 | Time: 0.0m 26.65s\n",
      "\t Train Loss: 1.340 | Train Acc: 16.40%\n",
      "\t Val. Loss: 1.631 |  Val. Acc: 23.46%\n",
      "\t Relaxed Train. Acc: 70.35% | Relaxed Val. Acc: 65.07%\n",
      "Epoch: 20 | Time: 0.0m 26.64s\n",
      "\t Train Loss: 1.330 | Train Acc: 16.82%\n",
      "\t Val. Loss: 1.630 |  Val. Acc: 22.34%\n",
      "\t Relaxed Train. Acc: 70.66% | Relaxed Val. Acc: 64.98%\n",
      "Run: enc_embed size: 64 dec_embed size: 64, hid_size: 32, num_layers: 1, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>relxd train acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>relxd valid acc</td><td>▁▃▄▅▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>train acc</td><td>▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>valid loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>relxd train acc</td><td>0.70655</td></tr><tr><td>relxd valid acc</td><td>0.64979</td></tr><tr><td>train acc</td><td>0.16824</td></tr><tr><td>train loss</td><td>1.3295</td></tr><tr><td>valid acc</td><td>0.22339</td></tr><tr><td>valid loss</td><td>1.63023</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-sweep-38</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/r21kns0f' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/r21kns0f</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_004001-r21kns0f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s1huhmdf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_004910-s1huhmdf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/s1huhmdf' target=\"_blank\">logical-sweep-39</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/s1huhmdf' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/s1huhmdf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 60,068 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 42.21s\n",
      "\t Train Loss: 3.026 | Train Acc: 0.00%\n",
      "\t Val. Loss: 2.791 |  Val. Acc: 0.12%\n",
      "\t Relaxed Train. Acc: 24.92% | Relaxed Val. Acc: 33.08%\n",
      "Epoch: 02 | Time: 0.0m 42.25s\n",
      "\t Train Loss: 2.536 | Train Acc: 0.06%\n",
      "\t Val. Loss: 2.387 |  Val. Acc: 1.17%\n",
      "\t Relaxed Train. Acc: 35.87% | Relaxed Val. Acc: 42.83%\n",
      "Epoch: 03 | Time: 0.0m 42.24s\n",
      "\t Train Loss: 2.288 | Train Acc: 0.27%\n",
      "\t Val. Loss: 2.203 |  Val. Acc: 2.69%\n",
      "\t Relaxed Train. Acc: 41.98% | Relaxed Val. Acc: 47.70%\n",
      "Epoch: 04 | Time: 0.0m 42.25s\n",
      "\t Train Loss: 2.141 | Train Acc: 0.57%\n",
      "\t Val. Loss: 2.081 |  Val. Acc: 4.57%\n",
      "\t Relaxed Train. Acc: 46.05% | Relaxed Val. Acc: 51.31%\n",
      "Epoch: 05 | Time: 0.0m 42.25s\n",
      "\t Train Loss: 2.040 | Train Acc: 1.10%\n",
      "\t Val. Loss: 1.987 |  Val. Acc: 6.25%\n",
      "\t Relaxed Train. Acc: 48.83% | Relaxed Val. Acc: 53.55%\n",
      "Epoch: 06 | Time: 0.0m 42.19s\n",
      "\t Train Loss: 1.965 | Train Acc: 1.78%\n",
      "\t Val. Loss: 1.932 |  Val. Acc: 7.84%\n",
      "\t Relaxed Train. Acc: 50.90% | Relaxed Val. Acc: 55.19%\n",
      "Epoch: 07 | Time: 0.0m 42.24s\n",
      "\t Train Loss: 1.908 | Train Acc: 2.34%\n",
      "\t Val. Loss: 1.891 |  Val. Acc: 9.06%\n",
      "\t Relaxed Train. Acc: 52.62% | Relaxed Val. Acc: 56.20%\n",
      "Epoch: 08 | Time: 0.0m 42.17s\n",
      "\t Train Loss: 1.864 | Train Acc: 2.79%\n",
      "\t Val. Loss: 1.871 |  Val. Acc: 11.13%\n",
      "\t Relaxed Train. Acc: 53.96% | Relaxed Val. Acc: 57.61%\n",
      "Epoch: 09 | Time: 0.0m 42.18s\n",
      "\t Train Loss: 1.834 | Train Acc: 3.35%\n",
      "\t Val. Loss: 1.829 |  Val. Acc: 10.86%\n",
      "\t Relaxed Train. Acc: 54.83% | Relaxed Val. Acc: 57.76%\n",
      "Epoch: 10 | Time: 0.0m 42.21s\n",
      "\t Train Loss: 1.802 | Train Acc: 3.79%\n",
      "\t Val. Loss: 1.821 |  Val. Acc: 12.89%\n",
      "\t Relaxed Train. Acc: 55.75% | Relaxed Val. Acc: 58.58%\n",
      "Run: enc_embed size: 16 dec_embed size: 128, hid_size: 16, num_layers: 3, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>relxd train acc</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>relxd valid acc</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train acc</td><td>▁▁▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>valid acc</td><td>▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>valid loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>relxd train acc</td><td>0.55751</td></tr><tr><td>relxd valid acc</td><td>0.58576</td></tr><tr><td>train acc</td><td>0.03795</td></tr><tr><td>train loss</td><td>1.80175</td></tr><tr><td>valid acc</td><td>0.12891</td></tr><tr><td>valid loss</td><td>1.82106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-39</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/s1huhmdf' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/s1huhmdf</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_004910-s1huhmdf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 51kp3rdm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_005625-51kp3rdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/51kp3rdm' target=\"_blank\">woven-sweep-40</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/51kp3rdm' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/51kp3rdm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 41,988 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 40.48s\n",
      "\t Train Loss: 2.784 | Train Acc: 0.04%\n",
      "\t Val. Loss: 2.530 |  Val. Acc: 0.83%\n",
      "\t Relaxed Train. Acc: 33.57% | Relaxed Val. Acc: 42.64%\n",
      "Epoch: 02 | Time: 0.0m 40.44s\n",
      "\t Train Loss: 2.430 | Train Acc: 0.21%\n",
      "\t Val. Loss: 2.327 |  Val. Acc: 1.86%\n",
      "\t Relaxed Train. Acc: 41.35% | Relaxed Val. Acc: 46.09%\n",
      "Epoch: 03 | Time: 0.0m 40.44s\n",
      "\t Train Loss: 2.275 | Train Acc: 0.55%\n",
      "\t Val. Loss: 2.213 |  Val. Acc: 3.83%\n",
      "\t Relaxed Train. Acc: 44.38% | Relaxed Val. Acc: 48.77%\n",
      "Epoch: 04 | Time: 0.0m 40.51s\n",
      "\t Train Loss: 2.176 | Train Acc: 0.96%\n",
      "\t Val. Loss: 2.120 |  Val. Acc: 4.49%\n",
      "\t Relaxed Train. Acc: 46.66% | Relaxed Val. Acc: 50.65%\n",
      "Epoch: 05 | Time: 0.0m 40.41s\n",
      "\t Train Loss: 2.094 | Train Acc: 1.46%\n",
      "\t Val. Loss: 2.076 |  Val. Acc: 5.13%\n",
      "\t Relaxed Train. Acc: 48.54% | Relaxed Val. Acc: 51.86%\n",
      "Epoch: 06 | Time: 0.0m 40.43s\n",
      "\t Train Loss: 2.028 | Train Acc: 2.01%\n",
      "\t Val. Loss: 2.034 |  Val. Acc: 7.01%\n",
      "\t Relaxed Train. Acc: 50.33% | Relaxed Val. Acc: 53.72%\n",
      "Epoch: 07 | Time: 0.0m 40.42s\n",
      "\t Train Loss: 1.979 | Train Acc: 2.34%\n",
      "\t Val. Loss: 1.988 |  Val. Acc: 6.98%\n",
      "\t Relaxed Train. Acc: 51.54% | Relaxed Val. Acc: 54.39%\n",
      "Epoch: 08 | Time: 0.0m 40.40s\n",
      "\t Train Loss: 1.941 | Train Acc: 2.75%\n",
      "\t Val. Loss: 1.971 |  Val. Acc: 8.33%\n",
      "\t Relaxed Train. Acc: 52.49% | Relaxed Val. Acc: 55.31%\n",
      "Epoch: 09 | Time: 0.0m 40.42s\n",
      "\t Train Loss: 1.906 | Train Acc: 3.11%\n",
      "\t Val. Loss: 1.956 |  Val. Acc: 7.59%\n",
      "\t Relaxed Train. Acc: 53.40% | Relaxed Val. Acc: 54.13%\n",
      "Epoch: 10 | Time: 0.0m 40.46s\n",
      "\t Train Loss: 1.873 | Train Acc: 3.54%\n",
      "\t Val. Loss: 1.902 |  Val. Acc: 9.79%\n",
      "\t Relaxed Train. Acc: 54.31% | Relaxed Val. Acc: 56.80%\n",
      "Run: enc_embed size: 64 dec_embed size: 16, hid_size: 32, num_layers: 3, cell_modernn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>relxd train acc</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>relxd valid acc</td><td>▁▃▄▅▆▆▇▇▇█</td></tr><tr><td>train acc</td><td>▁▁▂▃▄▅▆▆▇█</td></tr><tr><td>train loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>valid acc</td><td>▁▂▃▄▄▆▆▇▆█</td></tr><tr><td>valid loss</td><td>█▆▄▃▃▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>relxd train acc</td><td>0.54305</td></tr><tr><td>relxd valid acc</td><td>0.56803</td></tr><tr><td>train acc</td><td>0.03535</td></tr><tr><td>train loss</td><td>1.87341</td></tr><tr><td>valid acc</td><td>0.0979</td></tr><tr><td>valid loss</td><td>1.90214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-40</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/51kp3rdm' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/51kp3rdm</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_005625-51kp3rdm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: so718mic with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_010322-so718mic</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/so718mic' target=\"_blank\">easy-sweep-41</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/so718mic' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/so718mic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 630,724 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 32.33s\n",
      "\t Train Loss: 2.502 | Train Acc: 0.30%\n",
      "\t Val. Loss: 2.443 |  Val. Acc: 2.27%\n",
      "\t Relaxed Train. Acc: 40.77% | Relaxed Val. Acc: 46.03%\n",
      "Epoch: 02 | Time: 0.0m 32.32s\n",
      "\t Train Loss: 2.259 | Train Acc: 0.68%\n",
      "\t Val. Loss: 2.366 |  Val. Acc: 2.93%\n",
      "\t Relaxed Train. Acc: 45.93% | Relaxed Val. Acc: 47.15%\n",
      "Epoch: 03 | Time: 0.0m 32.38s\n",
      "\t Train Loss: 2.202 | Train Acc: 0.91%\n",
      "\t Val. Loss: 2.318 |  Val. Acc: 2.76%\n",
      "\t Relaxed Train. Acc: 47.28% | Relaxed Val. Acc: 47.76%\n",
      "Epoch: 04 | Time: 0.0m 32.39s\n",
      "\t Train Loss: 2.177 | Train Acc: 0.95%\n",
      "\t Val. Loss: 2.311 |  Val. Acc: 4.03%\n",
      "\t Relaxed Train. Acc: 47.74% | Relaxed Val. Acc: 48.60%\n",
      "Epoch: 05 | Time: 0.0m 32.39s\n",
      "\t Train Loss: 2.164 | Train Acc: 1.01%\n",
      "\t Val. Loss: 2.317 |  Val. Acc: 3.49%\n",
      "\t Relaxed Train. Acc: 48.11% | Relaxed Val. Acc: 48.46%\n",
      "Epoch: 06 | Time: 0.0m 32.39s\n",
      "\t Train Loss: 2.158 | Train Acc: 1.12%\n",
      "\t Val. Loss: 2.294 |  Val. Acc: 4.08%\n",
      "\t Relaxed Train. Acc: 48.36% | Relaxed Val. Acc: 49.02%\n",
      "Epoch: 07 | Time: 0.0m 32.39s\n",
      "\t Train Loss: 2.149 | Train Acc: 1.04%\n",
      "\t Val. Loss: 2.337 |  Val. Acc: 3.47%\n",
      "\t Relaxed Train. Acc: 48.53% | Relaxed Val. Acc: 48.55%\n",
      "Epoch: 08 | Time: 0.0m 32.38s\n",
      "\t Train Loss: 2.149 | Train Acc: 1.12%\n",
      "\t Val. Loss: 2.338 |  Val. Acc: 3.93%\n",
      "\t Relaxed Train. Acc: 48.55% | Relaxed Val. Acc: 49.00%\n",
      "Epoch: 09 | Time: 0.0m 32.38s\n",
      "\t Train Loss: 2.150 | Train Acc: 1.10%\n",
      "\t Val. Loss: 2.311 |  Val. Acc: 4.08%\n",
      "\t Relaxed Train. Acc: 48.51% | Relaxed Val. Acc: 48.48%\n",
      "Epoch: 10 | Time: 0.0m 32.40s\n",
      "\t Train Loss: 2.150 | Train Acc: 0.94%\n",
      "\t Val. Loss: 2.328 |  Val. Acc: 3.10%\n",
      "\t Relaxed Train. Acc: 48.62% | Relaxed Val. Acc: 48.13%\n",
      "Run: enc_embed size: 64 dec_embed size: 512, hid_size: 256, num_layers: 1, cell_modernn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>relxd train acc</td><td>▁▆▇▇██████</td></tr><tr><td>relxd valid acc</td><td>▁▄▅▇▇█▇█▇▆</td></tr><tr><td>train acc</td><td>▁▄▆▇▇█▇██▆</td></tr><tr><td>train loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▄▃█▆█▆▇█▄</td></tr><tr><td>valid loss</td><td>█▄▂▂▂▁▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>relxd train acc</td><td>0.48623</td></tr><tr><td>relxd valid acc</td><td>0.48135</td></tr><tr><td>train acc</td><td>0.00937</td></tr><tr><td>train loss</td><td>2.15008</td></tr><tr><td>valid acc</td><td>0.03101</td></tr><tr><td>valid loss</td><td>2.32841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-sweep-41</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/so718mic' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/so718mic</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_010322-so718mic/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: refwd3nq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_010900-refwd3nq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/refwd3nq' target=\"_blank\">feasible-sweep-42</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/refwd3nq' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/refwd3nq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 41,252 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 41.95s\n",
      "\t Train Loss: 2.982 | Train Acc: 0.00%\n",
      "\t Val. Loss: 2.711 |  Val. Acc: 0.20%\n",
      "\t Relaxed Train. Acc: 26.28% | Relaxed Val. Acc: 34.88%\n",
      "Epoch: 02 | Time: 0.0m 41.94s\n",
      "\t Train Loss: 2.457 | Train Acc: 0.13%\n",
      "\t Val. Loss: 2.318 |  Val. Acc: 1.78%\n",
      "\t Relaxed Train. Acc: 38.21% | Relaxed Val. Acc: 44.22%\n",
      "Epoch: 03 | Time: 0.0m 41.92s\n",
      "\t Train Loss: 2.207 | Train Acc: 0.51%\n",
      "\t Val. Loss: 2.128 |  Val. Acc: 4.22%\n",
      "\t Relaxed Train. Acc: 44.78% | Relaxed Val. Acc: 49.39%\n",
      "Epoch: 04 | Time: 0.0m 41.95s\n",
      "\t Train Loss: 2.072 | Train Acc: 1.07%\n",
      "\t Val. Loss: 2.047 |  Val. Acc: 5.83%\n",
      "\t Relaxed Train. Acc: 48.28% | Relaxed Val. Acc: 52.30%\n",
      "Epoch: 05 | Time: 0.0m 41.90s\n",
      "\t Train Loss: 1.984 | Train Acc: 1.64%\n",
      "\t Val. Loss: 1.975 |  Val. Acc: 7.20%\n",
      "\t Relaxed Train. Acc: 50.68% | Relaxed Val. Acc: 54.42%\n",
      "Epoch: 06 | Time: 0.0m 41.92s\n",
      "\t Train Loss: 1.921 | Train Acc: 2.27%\n",
      "\t Val. Loss: 1.920 |  Val. Acc: 8.40%\n",
      "\t Relaxed Train. Acc: 52.27% | Relaxed Val. Acc: 55.61%\n",
      "Epoch: 07 | Time: 0.0m 41.93s\n",
      "\t Train Loss: 1.868 | Train Acc: 2.86%\n",
      "\t Val. Loss: 1.882 |  Val. Acc: 9.18%\n",
      "\t Relaxed Train. Acc: 53.84% | Relaxed Val. Acc: 56.35%\n",
      "Epoch: 08 | Time: 0.0m 41.95s\n",
      "\t Train Loss: 1.829 | Train Acc: 3.34%\n",
      "\t Val. Loss: 1.866 |  Val. Acc: 10.30%\n",
      "\t Relaxed Train. Acc: 54.91% | Relaxed Val. Acc: 57.81%\n",
      "Epoch: 09 | Time: 0.0m 41.91s\n",
      "\t Train Loss: 1.796 | Train Acc: 3.98%\n",
      "\t Val. Loss: 1.811 |  Val. Acc: 10.72%\n",
      "\t Relaxed Train. Acc: 55.98% | Relaxed Val. Acc: 58.40%\n",
      "Epoch: 10 | Time: 0.0m 41.85s\n",
      "\t Train Loss: 1.765 | Train Acc: 4.36%\n",
      "\t Val. Loss: 1.809 |  Val. Acc: 10.64%\n",
      "\t Relaxed Train. Acc: 56.88% | Relaxed Val. Acc: 58.37%\n",
      "Epoch: 11 | Time: 0.0m 41.89s\n",
      "\t Train Loss: 1.742 | Train Acc: 4.87%\n",
      "\t Val. Loss: 1.815 |  Val. Acc: 12.38%\n",
      "\t Relaxed Train. Acc: 57.56% | Relaxed Val. Acc: 59.51%\n",
      "Epoch: 12 | Time: 0.0m 41.90s\n",
      "\t Train Loss: 1.717 | Train Acc: 5.29%\n",
      "\t Val. Loss: 1.760 |  Val. Acc: 13.18%\n",
      "\t Relaxed Train. Acc: 58.33% | Relaxed Val. Acc: 60.25%\n",
      "Epoch: 13 | Time: 0.0m 41.87s\n",
      "\t Train Loss: 1.693 | Train Acc: 5.72%\n",
      "\t Val. Loss: 1.761 |  Val. Acc: 14.43%\n",
      "\t Relaxed Train. Acc: 59.09% | Relaxed Val. Acc: 60.72%\n",
      "Epoch: 14 | Time: 0.0m 41.88s\n",
      "\t Train Loss: 1.670 | Train Acc: 6.23%\n",
      "\t Val. Loss: 1.750 |  Val. Acc: 15.62%\n",
      "\t Relaxed Train. Acc: 59.76% | Relaxed Val. Acc: 61.21%\n",
      "Epoch: 15 | Time: 0.0m 41.92s\n",
      "\t Train Loss: 1.659 | Train Acc: 6.60%\n",
      "\t Val. Loss: 1.716 |  Val. Acc: 14.84%\n",
      "\t Relaxed Train. Acc: 60.10% | Relaxed Val. Acc: 61.57%\n",
      "Epoch: 16 | Time: 0.0m 41.89s\n",
      "\t Train Loss: 1.640 | Train Acc: 7.05%\n",
      "\t Val. Loss: 1.704 |  Val. Acc: 15.72%\n",
      "\t Relaxed Train. Acc: 60.77% | Relaxed Val. Acc: 62.62%\n",
      "Epoch: 17 | Time: 0.0m 41.89s\n",
      "\t Train Loss: 1.627 | Train Acc: 7.40%\n",
      "\t Val. Loss: 1.697 |  Val. Acc: 16.85%\n",
      "\t Relaxed Train. Acc: 61.22% | Relaxed Val. Acc: 62.36%\n",
      "Epoch: 18 | Time: 0.0m 41.89s\n",
      "\t Train Loss: 1.612 | Train Acc: 7.61%\n",
      "\t Val. Loss: 1.680 |  Val. Acc: 17.70%\n",
      "\t Relaxed Train. Acc: 61.64% | Relaxed Val. Acc: 63.01%\n",
      "Epoch: 19 | Time: 0.0m 41.85s\n",
      "\t Train Loss: 1.595 | Train Acc: 8.13%\n",
      "\t Val. Loss: 1.682 |  Val. Acc: 17.50%\n",
      "\t Relaxed Train. Acc: 62.25% | Relaxed Val. Acc: 62.70%\n",
      "Epoch: 20 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.584 | Train Acc: 8.33%\n",
      "\t Val. Loss: 1.692 |  Val. Acc: 18.65%\n",
      "\t Relaxed Train. Acc: 62.49% | Relaxed Val. Acc: 62.81%\n",
      "Epoch: 21 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.575 | Train Acc: 8.56%\n",
      "\t Val. Loss: 1.665 |  Val. Acc: 18.60%\n",
      "\t Relaxed Train. Acc: 62.84% | Relaxed Val. Acc: 63.38%\n",
      "Epoch: 22 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.565 | Train Acc: 8.86%\n",
      "\t Val. Loss: 1.657 |  Val. Acc: 18.65%\n",
      "\t Relaxed Train. Acc: 63.11% | Relaxed Val. Acc: 63.63%\n",
      "Epoch: 23 | Time: 0.0m 41.84s\n",
      "\t Train Loss: 1.556 | Train Acc: 8.98%\n",
      "\t Val. Loss: 1.670 |  Val. Acc: 19.12%\n",
      "\t Relaxed Train. Acc: 63.39% | Relaxed Val. Acc: 63.81%\n",
      "Epoch: 24 | Time: 0.0m 41.83s\n",
      "\t Train Loss: 1.548 | Train Acc: 9.16%\n",
      "\t Val. Loss: 1.650 |  Val. Acc: 19.80%\n",
      "\t Relaxed Train. Acc: 63.65% | Relaxed Val. Acc: 63.87%\n",
      "Epoch: 25 | Time: 0.0m 41.84s\n",
      "\t Train Loss: 1.540 | Train Acc: 9.62%\n",
      "\t Val. Loss: 1.662 |  Val. Acc: 20.02%\n",
      "\t Relaxed Train. Acc: 63.97% | Relaxed Val. Acc: 64.38%\n",
      "Epoch: 26 | Time: 0.0m 41.85s\n",
      "\t Train Loss: 1.532 | Train Acc: 9.62%\n",
      "\t Val. Loss: 1.646 |  Val. Acc: 20.00%\n",
      "\t Relaxed Train. Acc: 64.16% | Relaxed Val. Acc: 64.48%\n",
      "Epoch: 27 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.528 | Train Acc: 9.74%\n",
      "\t Val. Loss: 1.656 |  Val. Acc: 20.07%\n",
      "\t Relaxed Train. Acc: 64.41% | Relaxed Val. Acc: 64.80%\n",
      "Epoch: 28 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.526 | Train Acc: 9.79%\n",
      "\t Val. Loss: 1.636 |  Val. Acc: 19.92%\n",
      "\t Relaxed Train. Acc: 64.32% | Relaxed Val. Acc: 64.58%\n",
      "Epoch: 29 | Time: 0.0m 41.84s\n",
      "\t Train Loss: 1.517 | Train Acc: 9.91%\n",
      "\t Val. Loss: 1.660 |  Val. Acc: 19.92%\n",
      "\t Relaxed Train. Acc: 64.68% | Relaxed Val. Acc: 64.88%\n",
      "Epoch: 30 | Time: 0.0m 41.86s\n",
      "\t Train Loss: 1.514 | Train Acc: 10.12%\n",
      "\t Val. Loss: 1.620 |  Val. Acc: 19.82%\n",
      "\t Relaxed Train. Acc: 64.72% | Relaxed Val. Acc: 64.88%\n",
      "Run: enc_embed size: 16 dec_embed size: 32, hid_size: 16, num_layers: 3, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>relxd valid acc</td><td>▁▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████</td></tr><tr><td>train acc</td><td>▁▁▁▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇█▇█████████</td></tr><tr><td>valid loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>29</td></tr><tr><td>relxd train acc</td><td>0.6472</td></tr><tr><td>relxd valid acc</td><td>0.64879</td></tr><tr><td>train acc</td><td>0.10119</td></tr><tr><td>train loss</td><td>1.51423</td></tr><tr><td>valid acc</td><td>0.19824</td></tr><tr><td>valid loss</td><td>1.62</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feasible-sweep-42</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/refwd3nq' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/refwd3nq</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_010900-refwd3nq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3p7jeokx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_013008-3p7jeokx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/3p7jeokx' target=\"_blank\">zany-sweep-43</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/3p7jeokx' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/3p7jeokx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 36,996 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 26.60s\n",
      "\t Train Loss: 2.810 | Train Acc: 0.03%\n",
      "\t Val. Loss: 2.701 |  Val. Acc: 0.54%\n",
      "\t Relaxed Train. Acc: 30.79% | Relaxed Val. Acc: 35.31%\n",
      "Epoch: 02 | Time: 0.0m 26.60s\n",
      "\t Train Loss: 2.419 | Train Acc: 0.16%\n",
      "\t Val. Loss: 2.499 |  Val. Acc: 0.78%\n",
      "\t Relaxed Train. Acc: 38.62% | Relaxed Val. Acc: 38.14%\n",
      "Epoch: 03 | Time: 0.0m 26.60s\n",
      "\t Train Loss: 2.271 | Train Acc: 0.46%\n",
      "\t Val. Loss: 2.391 |  Val. Acc: 1.73%\n",
      "\t Relaxed Train. Acc: 42.29% | Relaxed Val. Acc: 41.72%\n",
      "Epoch: 04 | Time: 0.0m 26.58s\n",
      "\t Train Loss: 2.168 | Train Acc: 0.81%\n",
      "\t Val. Loss: 2.319 |  Val. Acc: 2.81%\n",
      "\t Relaxed Train. Acc: 45.12% | Relaxed Val. Acc: 43.88%\n",
      "Epoch: 05 | Time: 0.0m 26.60s\n",
      "\t Train Loss: 2.106 | Train Acc: 1.12%\n",
      "\t Val. Loss: 2.252 |  Val. Acc: 3.44%\n",
      "\t Relaxed Train. Acc: 46.83% | Relaxed Val. Acc: 45.67%\n",
      "Epoch: 06 | Time: 0.0m 26.59s\n",
      "\t Train Loss: 2.045 | Train Acc: 1.52%\n",
      "\t Val. Loss: 2.185 |  Val. Acc: 4.13%\n",
      "\t Relaxed Train. Acc: 48.56% | Relaxed Val. Acc: 46.97%\n",
      "Epoch: 07 | Time: 0.0m 26.61s\n",
      "\t Train Loss: 1.993 | Train Acc: 1.93%\n",
      "\t Val. Loss: 2.146 |  Val. Acc: 5.69%\n",
      "\t Relaxed Train. Acc: 50.19% | Relaxed Val. Acc: 48.70%\n",
      "Epoch: 08 | Time: 0.0m 26.62s\n",
      "\t Train Loss: 1.957 | Train Acc: 2.32%\n",
      "\t Val. Loss: 2.130 |  Val. Acc: 5.93%\n",
      "\t Relaxed Train. Acc: 51.22% | Relaxed Val. Acc: 49.34%\n",
      "Epoch: 09 | Time: 0.0m 26.57s\n",
      "\t Train Loss: 1.930 | Train Acc: 2.64%\n",
      "\t Val. Loss: 2.087 |  Val. Acc: 6.05%\n",
      "\t Relaxed Train. Acc: 51.95% | Relaxed Val. Acc: 49.67%\n",
      "Epoch: 10 | Time: 0.0m 26.57s\n",
      "\t Train Loss: 1.901 | Train Acc: 2.95%\n",
      "\t Val. Loss: 2.067 |  Val. Acc: 7.03%\n",
      "\t Relaxed Train. Acc: 52.77% | Relaxed Val. Acc: 51.27%\n",
      "Epoch: 11 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.889 | Train Acc: 3.19%\n",
      "\t Val. Loss: 2.052 |  Val. Acc: 6.81%\n",
      "\t Relaxed Train. Acc: 53.13% | Relaxed Val. Acc: 51.27%\n",
      "Epoch: 12 | Time: 0.0m 26.55s\n",
      "\t Train Loss: 1.871 | Train Acc: 3.57%\n",
      "\t Val. Loss: 2.045 |  Val. Acc: 7.37%\n",
      "\t Relaxed Train. Acc: 53.75% | Relaxed Val. Acc: 51.97%\n",
      "Epoch: 13 | Time: 0.0m 26.57s\n",
      "\t Train Loss: 1.852 | Train Acc: 3.74%\n",
      "\t Val. Loss: 2.032 |  Val. Acc: 8.08%\n",
      "\t Relaxed Train. Acc: 54.27% | Relaxed Val. Acc: 52.53%\n",
      "Epoch: 14 | Time: 0.0m 26.59s\n",
      "\t Train Loss: 1.838 | Train Acc: 3.97%\n",
      "\t Val. Loss: 2.042 |  Val. Acc: 8.37%\n",
      "\t Relaxed Train. Acc: 54.83% | Relaxed Val. Acc: 51.95%\n",
      "Epoch: 15 | Time: 0.0m 26.55s\n",
      "\t Train Loss: 1.833 | Train Acc: 3.98%\n",
      "\t Val. Loss: 1.999 |  Val. Acc: 8.57%\n",
      "\t Relaxed Train. Acc: 54.82% | Relaxed Val. Acc: 52.75%\n",
      "Epoch: 16 | Time: 0.0m 26.56s\n",
      "\t Train Loss: 1.818 | Train Acc: 4.10%\n",
      "\t Val. Loss: 1.999 |  Val. Acc: 9.08%\n",
      "\t Relaxed Train. Acc: 55.28% | Relaxed Val. Acc: 53.39%\n",
      "Epoch: 17 | Time: 0.0m 41.31s\n",
      "\t Train Loss: 1.807 | Train Acc: 4.35%\n",
      "\t Val. Loss: 2.001 |  Val. Acc: 8.81%\n",
      "\t Relaxed Train. Acc: 55.64% | Relaxed Val. Acc: 53.11%\n",
      "Epoch: 18 | Time: 1.0m 29.53s\n",
      "\t Train Loss: 1.801 | Train Acc: 4.38%\n",
      "\t Val. Loss: 1.974 |  Val. Acc: 8.69%\n",
      "\t Relaxed Train. Acc: 55.84% | Relaxed Val. Acc: 53.46%\n",
      "Epoch: 19 | Time: 1.0m 29.57s\n",
      "\t Train Loss: 1.794 | Train Acc: 4.45%\n",
      "\t Val. Loss: 1.976 |  Val. Acc: 9.79%\n",
      "\t Relaxed Train. Acc: 56.05% | Relaxed Val. Acc: 53.99%\n",
      "Epoch: 20 | Time: 1.0m 29.50s\n",
      "\t Train Loss: 1.786 | Train Acc: 4.66%\n",
      "\t Val. Loss: 1.966 |  Val. Acc: 9.16%\n",
      "\t Relaxed Train. Acc: 56.35% | Relaxed Val. Acc: 54.24%\n",
      "Epoch: 21 | Time: 1.0m 21.82s\n",
      "\t Train Loss: 1.777 | Train Acc: 4.81%\n",
      "\t Val. Loss: 1.956 |  Val. Acc: 9.33%\n",
      "\t Relaxed Train. Acc: 56.59% | Relaxed Val. Acc: 54.15%\n",
      "Epoch: 22 | Time: 1.0m 27.70s\n",
      "\t Train Loss: 1.771 | Train Acc: 4.90%\n",
      "\t Val. Loss: 1.951 |  Val. Acc: 9.69%\n",
      "\t Relaxed Train. Acc: 56.80% | Relaxed Val. Acc: 54.38%\n",
      "Epoch: 23 | Time: 1.0m 27.54s\n",
      "\t Train Loss: 1.769 | Train Acc: 4.95%\n",
      "\t Val. Loss: 1.960 |  Val. Acc: 9.16%\n",
      "\t Relaxed Train. Acc: 56.87% | Relaxed Val. Acc: 53.42%\n",
      "Epoch: 24 | Time: 1.0m 27.34s\n",
      "\t Train Loss: 1.761 | Train Acc: 5.07%\n",
      "\t Val. Loss: 1.948 |  Val. Acc: 9.30%\n",
      "\t Relaxed Train. Acc: 57.16% | Relaxed Val. Acc: 54.61%\n",
      "Epoch: 25 | Time: 0.0m 34.17s\n",
      "\t Train Loss: 1.757 | Train Acc: 5.25%\n",
      "\t Val. Loss: 1.974 |  Val. Acc: 10.11%\n",
      "\t Relaxed Train. Acc: 57.27% | Relaxed Val. Acc: 54.88%\n",
      "Epoch: 26 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.749 | Train Acc: 5.24%\n",
      "\t Val. Loss: 1.943 |  Val. Acc: 10.06%\n",
      "\t Relaxed Train. Acc: 57.52% | Relaxed Val. Acc: 55.02%\n",
      "Epoch: 27 | Time: 0.0m 26.63s\n",
      "\t Train Loss: 1.748 | Train Acc: 5.35%\n",
      "\t Val. Loss: 1.927 |  Val. Acc: 10.16%\n",
      "\t Relaxed Train. Acc: 57.46% | Relaxed Val. Acc: 55.37%\n",
      "Epoch: 28 | Time: 0.0m 26.73s\n",
      "\t Train Loss: 1.742 | Train Acc: 5.49%\n",
      "\t Val. Loss: 1.935 |  Val. Acc: 9.89%\n",
      "\t Relaxed Train. Acc: 57.73% | Relaxed Val. Acc: 54.42%\n",
      "Epoch: 29 | Time: 0.0m 26.52s\n",
      "\t Train Loss: 1.737 | Train Acc: 5.57%\n",
      "\t Val. Loss: 1.938 |  Val. Acc: 10.55%\n",
      "\t Relaxed Train. Acc: 57.88% | Relaxed Val. Acc: 55.10%\n",
      "Epoch: 30 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.735 | Train Acc: 5.55%\n",
      "\t Val. Loss: 1.918 |  Val. Acc: 11.13%\n",
      "\t Relaxed Train. Acc: 57.92% | Relaxed Val. Acc: 55.45%\n",
      "Epoch: 31 | Time: 0.0m 26.55s\n",
      "\t Train Loss: 1.727 | Train Acc: 5.76%\n",
      "\t Val. Loss: 1.917 |  Val. Acc: 11.23%\n",
      "\t Relaxed Train. Acc: 58.22% | Relaxed Val. Acc: 55.84%\n",
      "Epoch: 32 | Time: 0.0m 28.43s\n",
      "\t Train Loss: 1.720 | Train Acc: 5.85%\n",
      "\t Val. Loss: 1.911 |  Val. Acc: 11.13%\n",
      "\t Relaxed Train. Acc: 58.42% | Relaxed Val. Acc: 56.43%\n",
      "Epoch: 33 | Time: 0.0m 26.59s\n",
      "\t Train Loss: 1.716 | Train Acc: 5.93%\n",
      "\t Val. Loss: 1.918 |  Val. Acc: 11.35%\n",
      "\t Relaxed Train. Acc: 58.53% | Relaxed Val. Acc: 55.80%\n",
      "Epoch: 34 | Time: 0.0m 26.52s\n",
      "\t Train Loss: 1.716 | Train Acc: 6.05%\n",
      "\t Val. Loss: 1.891 |  Val. Acc: 11.47%\n",
      "\t Relaxed Train. Acc: 58.61% | Relaxed Val. Acc: 56.36%\n",
      "Epoch: 35 | Time: 1.0m 11.92s\n",
      "\t Train Loss: 1.713 | Train Acc: 6.15%\n",
      "\t Val. Loss: 1.905 |  Val. Acc: 10.86%\n",
      "\t Relaxed Train. Acc: 58.65% | Relaxed Val. Acc: 56.57%\n",
      "Epoch: 36 | Time: 0.0m 28.97s\n",
      "\t Train Loss: 1.708 | Train Acc: 6.38%\n",
      "\t Val. Loss: 1.892 |  Val. Acc: 11.96%\n",
      "\t Relaxed Train. Acc: 58.82% | Relaxed Val. Acc: 56.50%\n",
      "Epoch: 37 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.704 | Train Acc: 6.43%\n",
      "\t Val. Loss: 1.899 |  Val. Acc: 12.52%\n",
      "\t Relaxed Train. Acc: 59.02% | Relaxed Val. Acc: 57.06%\n",
      "Epoch: 38 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.701 | Train Acc: 6.52%\n",
      "\t Val. Loss: 1.894 |  Val. Acc: 12.08%\n",
      "\t Relaxed Train. Acc: 59.08% | Relaxed Val. Acc: 56.50%\n",
      "Epoch: 39 | Time: 0.0m 26.56s\n",
      "\t Train Loss: 1.692 | Train Acc: 6.63%\n",
      "\t Val. Loss: 1.884 |  Val. Acc: 11.69%\n",
      "\t Relaxed Train. Acc: 59.31% | Relaxed Val. Acc: 56.67%\n",
      "Epoch: 40 | Time: 0.0m 26.54s\n",
      "\t Train Loss: 1.690 | Train Acc: 6.72%\n",
      "\t Val. Loss: 1.903 |  Val. Acc: 11.62%\n",
      "\t Relaxed Train. Acc: 59.37% | Relaxed Val. Acc: 56.49%\n",
      "Run: enc_embed size: 32 dec_embed size: 128, hid_size: 16, num_layers: 1, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>relxd valid acc</td><td>▁▂▃▄▄▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train acc</td><td>▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇████▇</td></tr><tr><td>valid loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>relxd train acc</td><td>0.59368</td></tr><tr><td>relxd valid acc</td><td>0.56489</td></tr><tr><td>train acc</td><td>0.06717</td></tr><tr><td>train loss</td><td>1.68957</td></tr><tr><td>valid acc</td><td>0.11621</td></tr><tr><td>valid loss</td><td>1.90259</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-43</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/3p7jeokx' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/3p7jeokx</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_013008-3p7jeokx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bx5ks9i5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_015623-bx5ks9i5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/bx5ks9i5' target=\"_blank\">summer-sweep-44</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/bx5ks9i5' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/bx5ks9i5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,377,220 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 35.71s\n",
      "\t Train Loss: 1.613 | Train Acc: 10.81%\n",
      "\t Val. Loss: 1.555 |  Val. Acc: 25.20%\n",
      "\t Relaxed Train. Acc: 61.98% | Relaxed Val. Acc: 67.22%\n",
      "Epoch: 02 | Time: 0.0m 35.71s\n",
      "\t Train Loss: 1.165 | Train Acc: 23.43%\n",
      "\t Val. Loss: 1.453 |  Val. Acc: 29.98%\n",
      "\t Relaxed Train. Acc: 75.61% | Relaxed Val. Acc: 71.01%\n",
      "Epoch: 03 | Time: 0.0m 35.63s\n",
      "\t Train Loss: 1.044 | Train Acc: 30.18%\n",
      "\t Val. Loss: 1.441 |  Val. Acc: 32.15%\n",
      "\t Relaxed Train. Acc: 79.72% | Relaxed Val. Acc: 72.34%\n",
      "Epoch: 04 | Time: 0.0m 35.56s\n",
      "\t Train Loss: 0.973 | Train Acc: 34.87%\n",
      "\t Val. Loss: 1.417 |  Val. Acc: 34.23%\n",
      "\t Relaxed Train. Acc: 82.06% | Relaxed Val. Acc: 73.28%\n",
      "Epoch: 05 | Time: 0.0m 35.53s\n",
      "\t Train Loss: 0.919 | Train Acc: 39.37%\n",
      "\t Val. Loss: 1.483 |  Val. Acc: 31.86%\n",
      "\t Relaxed Train. Acc: 84.01% | Relaxed Val. Acc: 72.29%\n",
      "Epoch: 06 | Time: 0.0m 35.48s\n",
      "\t Train Loss: 0.879 | Train Acc: 42.44%\n",
      "\t Val. Loss: 1.522 |  Val. Acc: 33.74%\n",
      "\t Relaxed Train. Acc: 85.34% | Relaxed Val. Acc: 72.39%\n",
      "Epoch: 07 | Time: 0.0m 35.45s\n",
      "\t Train Loss: 0.839 | Train Acc: 45.68%\n",
      "\t Val. Loss: 1.517 |  Val. Acc: 34.23%\n",
      "\t Relaxed Train. Acc: 86.65% | Relaxed Val. Acc: 72.63%\n",
      "Epoch: 08 | Time: 0.0m 35.41s\n",
      "\t Train Loss: 0.816 | Train Acc: 48.28%\n",
      "\t Val. Loss: 1.575 |  Val. Acc: 34.03%\n",
      "\t Relaxed Train. Acc: 87.44% | Relaxed Val. Acc: 72.35%\n",
      "Epoch: 09 | Time: 0.0m 35.39s\n",
      "\t Train Loss: 0.796 | Train Acc: 50.37%\n",
      "\t Val. Loss: 1.590 |  Val. Acc: 33.01%\n",
      "\t Relaxed Train. Acc: 88.14% | Relaxed Val. Acc: 72.20%\n",
      "Epoch: 10 | Time: 0.0m 35.38s\n",
      "\t Train Loss: 0.776 | Train Acc: 52.09%\n",
      "\t Val. Loss: 1.608 |  Val. Acc: 33.42%\n",
      "\t Relaxed Train. Acc: 88.74% | Relaxed Val. Acc: 72.64%\n",
      "Epoch: 11 | Time: 0.0m 35.36s\n",
      "\t Train Loss: 0.769 | Train Acc: 53.43%\n",
      "\t Val. Loss: 1.622 |  Val. Acc: 34.81%\n",
      "\t Relaxed Train. Acc: 88.99% | Relaxed Val. Acc: 72.97%\n",
      "Epoch: 12 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.758 | Train Acc: 54.75%\n",
      "\t Val. Loss: 1.632 |  Val. Acc: 32.23%\n",
      "\t Relaxed Train. Acc: 89.40% | Relaxed Val. Acc: 72.84%\n",
      "Epoch: 13 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.748 | Train Acc: 55.87%\n",
      "\t Val. Loss: 1.675 |  Val. Acc: 33.37%\n",
      "\t Relaxed Train. Acc: 89.78% | Relaxed Val. Acc: 72.69%\n",
      "Epoch: 14 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.742 | Train Acc: 56.25%\n",
      "\t Val. Loss: 1.653 |  Val. Acc: 32.76%\n",
      "\t Relaxed Train. Acc: 89.90% | Relaxed Val. Acc: 72.36%\n",
      "Epoch: 15 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.744 | Train Acc: 57.04%\n",
      "\t Val. Loss: 1.673 |  Val. Acc: 32.30%\n",
      "\t Relaxed Train. Acc: 89.96% | Relaxed Val. Acc: 71.99%\n",
      "Epoch: 16 | Time: 0.0m 35.31s\n",
      "\t Train Loss: 0.730 | Train Acc: 57.70%\n",
      "\t Val. Loss: 1.677 |  Val. Acc: 32.08%\n",
      "\t Relaxed Train. Acc: 90.34% | Relaxed Val. Acc: 72.67%\n",
      "Epoch: 17 | Time: 0.0m 35.31s\n",
      "\t Train Loss: 0.727 | Train Acc: 58.07%\n",
      "\t Val. Loss: 1.677 |  Val. Acc: 32.25%\n",
      "\t Relaxed Train. Acc: 90.49% | Relaxed Val. Acc: 72.92%\n",
      "Epoch: 18 | Time: 0.0m 35.30s\n",
      "\t Train Loss: 0.728 | Train Acc: 58.47%\n",
      "\t Val. Loss: 1.699 |  Val. Acc: 33.35%\n",
      "\t Relaxed Train. Acc: 90.44% | Relaxed Val. Acc: 72.51%\n",
      "Epoch: 19 | Time: 0.0m 35.30s\n",
      "\t Train Loss: 0.727 | Train Acc: 58.54%\n",
      "\t Val. Loss: 1.718 |  Val. Acc: 32.15%\n",
      "\t Relaxed Train. Acc: 90.46% | Relaxed Val. Acc: 72.05%\n",
      "Epoch: 20 | Time: 0.0m 35.30s\n",
      "\t Train Loss: 0.725 | Train Acc: 58.68%\n",
      "\t Val. Loss: 1.746 |  Val. Acc: 31.64%\n",
      "\t Relaxed Train. Acc: 90.54% | Relaxed Val. Acc: 71.83%\n",
      "Epoch: 21 | Time: 0.0m 35.29s\n",
      "\t Train Loss: 0.725 | Train Acc: 58.81%\n",
      "\t Val. Loss: 1.727 |  Val. Acc: 31.69%\n",
      "\t Relaxed Train. Acc: 90.52% | Relaxed Val. Acc: 71.83%\n",
      "Epoch: 22 | Time: 0.0m 35.30s\n",
      "\t Train Loss: 0.722 | Train Acc: 58.95%\n",
      "\t Val. Loss: 1.705 |  Val. Acc: 32.54%\n",
      "\t Relaxed Train. Acc: 90.66% | Relaxed Val. Acc: 72.66%\n",
      "Epoch: 23 | Time: 0.0m 35.29s\n",
      "\t Train Loss: 0.723 | Train Acc: 58.92%\n",
      "\t Val. Loss: 1.742 |  Val. Acc: 32.01%\n",
      "\t Relaxed Train. Acc: 90.58% | Relaxed Val. Acc: 72.27%\n",
      "Epoch: 24 | Time: 0.0m 59.50s\n",
      "\t Train Loss: 0.734 | Train Acc: 57.98%\n",
      "\t Val. Loss: 1.733 |  Val. Acc: 30.96%\n",
      "\t Relaxed Train. Acc: 90.23% | Relaxed Val. Acc: 71.92%\n",
      "Epoch: 25 | Time: 1.0m 24.27s\n",
      "\t Train Loss: 0.725 | Train Acc: 58.77%\n",
      "\t Val. Loss: 1.747 |  Val. Acc: 31.69%\n",
      "\t Relaxed Train. Acc: 90.56% | Relaxed Val. Acc: 72.11%\n",
      "Epoch: 26 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.727 | Train Acc: 58.81%\n",
      "\t Val. Loss: 1.714 |  Val. Acc: 31.13%\n",
      "\t Relaxed Train. Acc: 90.53% | Relaxed Val. Acc: 72.40%\n",
      "Epoch: 27 | Time: 0.0m 35.35s\n",
      "\t Train Loss: 0.728 | Train Acc: 58.68%\n",
      "\t Val. Loss: 1.747 |  Val. Acc: 31.69%\n",
      "\t Relaxed Train. Acc: 90.50% | Relaxed Val. Acc: 72.19%\n",
      "Epoch: 28 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.734 | Train Acc: 57.98%\n",
      "\t Val. Loss: 1.707 |  Val. Acc: 31.69%\n",
      "\t Relaxed Train. Acc: 90.26% | Relaxed Val. Acc: 72.14%\n",
      "Epoch: 29 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.730 | Train Acc: 58.31%\n",
      "\t Val. Loss: 1.755 |  Val. Acc: 30.79%\n",
      "\t Relaxed Train. Acc: 90.35% | Relaxed Val. Acc: 71.83%\n",
      "Epoch: 30 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.733 | Train Acc: 57.93%\n",
      "\t Val. Loss: 1.734 |  Val. Acc: 31.05%\n",
      "\t Relaxed Train. Acc: 90.28% | Relaxed Val. Acc: 71.92%\n",
      "Epoch: 31 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.732 | Train Acc: 58.43%\n",
      "\t Val. Loss: 1.749 |  Val. Acc: 30.44%\n",
      "\t Relaxed Train. Acc: 90.36% | Relaxed Val. Acc: 71.65%\n",
      "Epoch: 32 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.734 | Train Acc: 58.23%\n",
      "\t Val. Loss: 1.763 |  Val. Acc: 30.54%\n",
      "\t Relaxed Train. Acc: 90.24% | Relaxed Val. Acc: 71.25%\n",
      "Epoch: 33 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.739 | Train Acc: 57.47%\n",
      "\t Val. Loss: 1.763 |  Val. Acc: 30.49%\n",
      "\t Relaxed Train. Acc: 90.06% | Relaxed Val. Acc: 71.61%\n",
      "Epoch: 34 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.741 | Train Acc: 57.17%\n",
      "\t Val. Loss: 1.741 |  Val. Acc: 32.08%\n",
      "\t Relaxed Train. Acc: 90.01% | Relaxed Val. Acc: 72.05%\n",
      "Epoch: 35 | Time: 0.0m 35.33s\n",
      "\t Train Loss: 0.739 | Train Acc: 57.58%\n",
      "\t Val. Loss: 1.776 |  Val. Acc: 29.17%\n",
      "\t Relaxed Train. Acc: 90.07% | Relaxed Val. Acc: 71.14%\n",
      "Epoch: 36 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.744 | Train Acc: 57.20%\n",
      "\t Val. Loss: 1.746 |  Val. Acc: 30.47%\n",
      "\t Relaxed Train. Acc: 89.91% | Relaxed Val. Acc: 71.64%\n",
      "Epoch: 37 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.745 | Train Acc: 57.10%\n",
      "\t Val. Loss: 1.728 |  Val. Acc: 32.18%\n",
      "\t Relaxed Train. Acc: 89.84% | Relaxed Val. Acc: 72.01%\n",
      "Epoch: 38 | Time: 0.0m 35.31s\n",
      "\t Train Loss: 0.743 | Train Acc: 57.50%\n",
      "\t Val. Loss: 1.770 |  Val. Acc: 30.74%\n",
      "\t Relaxed Train. Acc: 89.95% | Relaxed Val. Acc: 70.80%\n",
      "Epoch: 39 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.742 | Train Acc: 56.87%\n",
      "\t Val. Loss: 1.732 |  Val. Acc: 31.30%\n",
      "\t Relaxed Train. Acc: 89.93% | Relaxed Val. Acc: 71.80%\n",
      "Epoch: 40 | Time: 0.0m 35.32s\n",
      "\t Train Loss: 0.748 | Train Acc: 56.54%\n",
      "\t Val. Loss: 1.724 |  Val. Acc: 29.54%\n",
      "\t Relaxed Train. Acc: 89.72% | Relaxed Val. Acc: 71.51%\n",
      "Run: enc_embed size: 32 dec_embed size: 16, hid_size: 512, num_layers: 1, cell_modegru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>relxd train acc</td><td>▁▄▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>relxd valid acc</td><td>▁▅▇█▇▇▇▇▇▇█▇▇▇▇▇█▇▇▆▆▇▇▆▇▇▇▇▆▆▆▆▆▇▆▆▇▅▆▆</td></tr><tr><td>train acc</td><td>▁▃▄▄▅▆▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>train loss</td><td>█▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▄▆█▆▇█▇▇▇█▆▇▇▆▆▆▇▆▆▆▆▆▅▆▅▆▆▅▅▅▅▅▆▄▅▆▅▅▄</td></tr><tr><td>valid loss</td><td>▄▂▁▁▂▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>relxd train acc</td><td>0.8972</td></tr><tr><td>relxd valid acc</td><td>0.71511</td></tr><tr><td>train acc</td><td>0.56543</td></tr><tr><td>train loss</td><td>0.74784</td></tr><tr><td>valid acc</td><td>0.29541</td></tr><tr><td>valid loss</td><td>1.72394</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-44</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/bx5ks9i5' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/bx5ks9i5</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_015623-bx5ks9i5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4g6oidjq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_022134-4g6oidjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/4g6oidjq' target=\"_blank\">northern-sweep-45</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/4g6oidjq' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/4g6oidjq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,845,060 trainable parameters\n",
      "Epoch: 01 | Time: 1.0m 15.99s\n",
      "\t Train Loss: 2.805 | Train Acc: 0.14%\n",
      "\t Val. Loss: 2.100 |  Val. Acc: 5.57%\n",
      "\t Relaxed Train. Acc: 30.55% | Relaxed Val. Acc: 51.95%\n",
      "Epoch: 02 | Time: 1.0m 16.27s\n",
      "\t Train Loss: 1.528 | Train Acc: 10.30%\n",
      "\t Val. Loss: 1.526 |  Val. Acc: 25.37%\n",
      "\t Relaxed Train. Acc: 64.95% | Relaxed Val. Acc: 68.46%\n",
      "Epoch: 03 | Time: 1.0m 16.21s\n",
      "\t Train Loss: 1.199 | Train Acc: 20.51%\n",
      "\t Val. Loss: 1.441 |  Val. Acc: 31.49%\n",
      "\t Relaxed Train. Acc: 74.57% | Relaxed Val. Acc: 71.63%\n",
      "Epoch: 04 | Time: 1.0m 16.20s\n",
      "\t Train Loss: 1.077 | Train Acc: 26.84%\n",
      "\t Val. Loss: 1.407 |  Val. Acc: 34.96%\n",
      "\t Relaxed Train. Acc: 78.61% | Relaxed Val. Acc: 73.70%\n",
      "Epoch: 05 | Time: 1.0m 16.12s\n",
      "\t Train Loss: 1.011 | Train Acc: 31.34%\n",
      "\t Val. Loss: 1.389 |  Val. Acc: 35.42%\n",
      "\t Relaxed Train. Acc: 80.78% | Relaxed Val. Acc: 73.81%\n",
      "Epoch: 06 | Time: 1.0m 16.08s\n",
      "\t Train Loss: 0.957 | Train Acc: 34.91%\n",
      "\t Val. Loss: 1.382 |  Val. Acc: 37.82%\n",
      "\t Relaxed Train. Acc: 82.55% | Relaxed Val. Acc: 74.68%\n",
      "Epoch: 07 | Time: 1.0m 16.05s\n",
      "\t Train Loss: 0.912 | Train Acc: 38.26%\n",
      "\t Val. Loss: 1.370 |  Val. Acc: 38.01%\n",
      "\t Relaxed Train. Acc: 84.03% | Relaxed Val. Acc: 75.35%\n",
      "Epoch: 08 | Time: 1.0m 16.02s\n",
      "\t Train Loss: 0.876 | Train Acc: 40.83%\n",
      "\t Val. Loss: 1.379 |  Val. Acc: 39.09%\n",
      "\t Relaxed Train. Acc: 85.19% | Relaxed Val. Acc: 75.69%\n",
      "Epoch: 09 | Time: 1.0m 16.01s\n",
      "\t Train Loss: 0.847 | Train Acc: 43.73%\n",
      "\t Val. Loss: 1.399 |  Val. Acc: 37.26%\n",
      "\t Relaxed Train. Acc: 86.23% | Relaxed Val. Acc: 75.28%\n",
      "Epoch: 10 | Time: 1.0m 16.00s\n",
      "\t Train Loss: 0.822 | Train Acc: 46.02%\n",
      "\t Val. Loss: 1.395 |  Val. Acc: 38.48%\n",
      "\t Relaxed Train. Acc: 87.03% | Relaxed Val. Acc: 75.64%\n",
      "Run: enc_embed size: 128 dec_embed size: 16, hid_size: 512, num_layers: 3, cell_modelstm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>relxd train acc</td><td>▁▅▆▇▇▇████</td></tr><tr><td>relxd valid acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train acc</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>valid acc</td><td>▁▅▆▇▇█████</td></tr><tr><td>valid loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>relxd train acc</td><td>0.8703</td></tr><tr><td>relxd valid acc</td><td>0.75637</td></tr><tr><td>train acc</td><td>0.4602</td></tr><tr><td>train loss</td><td>0.82199</td></tr><tr><td>valid acc</td><td>0.38477</td></tr><tr><td>valid loss</td><td>1.39481</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-45</strong> at: <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/4g6oidjq' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/4g6oidjq</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230526_022134-4g6oidjq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yw20aj7u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_mode: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tis_bi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pragalbh/DL_Assign3/wandb/run-20230526_023428-yw20aj7u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pragalbh/DL_Assign3/runs/yw20aj7u' target=\"_blank\">fast-sweep-46</a></strong> to <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pragalbh/DL_Assign3' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/sweeps/1pfav8pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pragalbh/DL_Assign3/runs/yw20aj7u' target=\"_blank\">https://wandb.ai/pragalbh/DL_Assign3/runs/yw20aj7u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,424,580 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent('1pfav8pe',project=\"DL_Assign3\",entity=\"pragalbh\", function=sweeper, count=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweeper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya=SS(a['input'],a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5071c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_torchies(torchie1,index_toalp):\n",
    "    torchie=torchie1.cpu().numpy()\n",
    "    return word_from_vecs(torchie,index_toalp,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_batch(batch):\n",
    "    wordlet=[]\n",
    "    for i in range(len(batch)):\n",
    "        wordlet.append(word_from_torchies(batch[i],index_to_hindi_alphabet))\n",
    "    return wordlet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_torchies(bya.transpose(0,1).argmax(2)[0],index_to_hindi_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_hindi_alphabet[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wrd(stuff):\n",
    "    asa=[]\n",
    "    for k in stuff.cpu().numpy():\n",
    "        asa.append(index_to_hindi_alphabet[k])\n",
    "    return \"\".join(asa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_wrd(bya.transpose(0,1).argmax(2)[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32caa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bya.transpose(0,1).argmax(2)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print('................')\n",
    "    print(i)\n",
    "    print(word_from_torchies(a['output'][i],index_to_hindi_alphabet),\\\n",
    "         '---',\\\n",
    "         make_wrd(bya.transpose(0,1).argmax(2)[i])\\\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word (self, source_batch,target_batch):\n",
    "    max_len, batch_size = target_batch.shape\n",
    "    outputs = torch.zeros(max_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "\n",
    "            # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "    hidden, cell = self.encoder(source_batch)\n",
    "\n",
    "    wordet=[]\n",
    "\n",
    "\n",
    "    trg = torch.tensor(hindi_alphabet_to_index['<'])\n",
    "    trg=trg.to(device)\n",
    "    wordet.append(index_to_hindi_alphabet(trg.cpu().numpy()))\n",
    "    for i in range(1, max_len):\n",
    "        prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "        outputs[i] = prediction\n",
    "        trg = prediction.argmax(1)\n",
    "        wordet.append(index_to_hindi_alphabet(trg.cpu().numpy()))\n",
    "\n",
    "\n",
    "    return ''.join(wordet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ceca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_vecs(X_valid[0],index_to_english_alphabet,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_from_vecs(y_valid[0],index_to_hindi_alphabet,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc553c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b2342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "            for j in range(predicted.shape[1]):\n",
    "                predicted_seq = predicted[:, j]\n",
    "                targets_seq = target_seq[:, j]\n",
    "\n",
    "                # Find the index of the first EOS token in the sequence\n",
    "                eos_idx = (targets_seq == hin_token_map[\"\\n\"]).nonzero()\n",
    "                if eos_idx.numel() > 0:\n",
    "                    eos_idx = eos_idx[0][0]\n",
    "                    predicted_seq = predicted_seq[:eos_idx]\n",
    "                    targets_seq = targets_seq[:eos_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26653811",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
